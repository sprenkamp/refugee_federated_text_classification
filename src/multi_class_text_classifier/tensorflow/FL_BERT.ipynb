{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9ab8274a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-18 16:55:02.441578: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n"
     ]
    }
   ],
   "source": [
    "import collections\n",
    "from IPython.display import display\n",
    "from tensorflow import keras\n",
    "import pandas as pd\n",
    "from random import sample\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import os\n",
    "from tqdm import trange\n",
    "from random import sample\n",
    "from glob import glob\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.layers import MaxPooling2D\n",
    "from tensorflow.keras.layers import Activation\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Dense,LSTM,Dropout\n",
    "from tensorflow.compat.v1.keras.layers import CuDNNLSTM\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.metrics import MeanAbsoluteError,MeanSquaredError,RootMeanSquaredError,MeanAbsolutePercentageError\n",
    "import nest_asyncio\n",
    "from time import time\n",
    "import sys\n",
    "import tensorflow_federated as tff\n",
    "import uuid\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0aedce9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_sample(dataset,k=0.1):\n",
    "    return sample(dataset,int(k * len(dataset)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b12def24",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def create_tf_dataset_for_client_fn(path): # path is name of country the 'federator'\n",
    "    def batch_format_fn(element):\n",
    "\n",
    "        return collections.OrderedDict(\n",
    "            x=element['x'],\n",
    "            y=element['y'],)\n",
    "    #\n",
    "    data_x= np.load(f'{path}data_X.npy')\n",
    "    data_y= np.load(f'{path}data_Y.npy')\n",
    "\n",
    "    data = collections.OrderedDict((('y', data_y), ('x', data_x)))\n",
    "    dataset = tf.data.Dataset.from_tensor_slices(data)\n",
    "    return dataset.repeat(NUM_EPOCHS).batch(BATCH_SIZE).map(batch_format_fn).prefetch(PREFETCH_BUFFER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5a5f1360",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def get_training_Q(Q):\n",
    "    size = int(Q*len(train_data.client_ids))\n",
    "    sampled_clients = np.random.choice(\n",
    "            train_data.client_ids,\n",
    "            size=size,\n",
    "            replace=False)\n",
    "    \n",
    "    sampled_train_data = [\n",
    "            train_data.create_tf_dataset_for_client(client)\n",
    "            for client in sampled_clients\n",
    "        ]\n",
    "    \n",
    "    return sampled_train_data\n",
    "\n",
    "def get_test_Q(Q):\n",
    "    size = int(Q*len(test_data.client_ids))\n",
    "    sampled_clients = np.random.choice(\n",
    "            test_data.client_ids,\n",
    "            size=size,\n",
    "            replace=False)\n",
    "    \n",
    "    ids = [_id.split('/')[-3] for _id in sampled_clients]\n",
    "    print(ids)\n",
    "    \n",
    "    sampled_test_data = [\n",
    "            test_data.create_tf_dataset_for_client(client)\n",
    "            for client in sampled_clients\n",
    "        ]\n",
    "    return sampled_test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cf15b179",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_eval_dataset():\n",
    "    test_data_paths = glob('../Dataset/*/test/*/scaled/')\n",
    "    \n",
    "    dataset_test= []\n",
    "    for path in test_data_paths:\n",
    "        \n",
    "        d = dict(X= np.load(f'{path}data_X.npy'),\n",
    "                 y= np.load(f'{path}data_Y.npy'))    \n",
    "        dataset_test.append(d)\n",
    "        \n",
    "    dataset = {}\n",
    "    \n",
    "    dataset['X_test'] = np.concatenate([data['X'] for data in dataset_test],axis=0)\n",
    "    dataset['y_test'] = np.concatenate([data['y'] for data in dataset_test],axis=0)\n",
    "    \n",
    "    return dataset\n",
    "\n",
    "def evaluate_model(model):\n",
    "    X_test= eval_dataset['X_test']\n",
    "    y_test = eval_dataset['y_test']\n",
    "    \n",
    "    ev = model.evaluate(x=X_test,y=y_test,batch_size=2048,return_dict=True)\n",
    "    result  = pd.DataFrame(ev,index=[0])\n",
    "    return result\n",
    "\n",
    "def from_federated_to_keras(state):\n",
    "    federated_model = base_model()\n",
    "    federated_model.compile(optimizer=tf.keras.optimizers.SGD(learning_rate=1.0),\n",
    "                            loss=tf.keras.losses.MeanSquaredError(),\n",
    "                            metrics=[MeanAbsoluteError(), MeanSquaredError(), RootMeanSquaredError(),\n",
    "                                    MeanAbsolutePercentageError() \n",
    "                                    ])\n",
    "    state.model.assign_weights_to(model=federated_model)\n",
    "    return federated_model\n",
    "    \n",
    "def evaluate_federated_model(state):\n",
    "    federated_model = from_federated_to_keras(state)\n",
    "\n",
    "    return evaluate_model(federated_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3a93a697-1703-494c-b445-6f5596dbc179",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_in_text(path,model_fn):\n",
    "    m = model_fn()\n",
    "    with open(f'{path}model_report.txt','w') as fh:\n",
    "        m.summary(print_fn=lambda x: fh.write(x + '\\n'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "06c05641",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tff' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/kiliansprenkamp/Desktop/code/refugee_supervised_text_classification/src/multi_class_text_classifier/tensorflow/FL_BERT.ipynb Cell 7\u001b[0m in \u001b[0;36m<cell line: 40>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/kiliansprenkamp/Desktop/code/refugee_supervised_text_classification/src/multi_class_text_classifier/tensorflow/FL_BERT.ipynb#W6sZmlsZQ%3D%3D?line=35'>36</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m dataset\u001b[39m.\u001b[39mrepeat(NUM_EPOCHS)\u001b[39m.\u001b[39mbatch(BATCH_SIZE)\u001b[39m.\u001b[39mmap(batch_format_fn)\u001b[39m.\u001b[39mprefetch(PREFETCH_BUFFER)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/kiliansprenkamp/Desktop/code/refugee_supervised_text_classification/src/multi_class_text_classifier/tensorflow/FL_BERT.ipynb#W6sZmlsZQ%3D%3D?line=37'>38</a>\u001b[0m df_tf_sim \u001b[39m=\u001b[39mcreate_tf_dataset_for_client_fn(df, \u001b[39m\"\u001b[39m\u001b[39mgermany\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/kiliansprenkamp/Desktop/code/refugee_supervised_text_classification/src/multi_class_text_classifier/tensorflow/FL_BERT.ipynb#W6sZmlsZQ%3D%3D?line=39'>40</a>\u001b[0m train_data \u001b[39m=\u001b[39m tff\u001b[39m.\u001b[39msimulation\u001b[39m.\u001b[39mdatasets\u001b[39m.\u001b[39mClientData\u001b[39m.\u001b[39mfrom_clients_and_fn(\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/kiliansprenkamp/Desktop/code/refugee_supervised_text_classification/src/multi_class_text_classifier/tensorflow/FL_BERT.ipynb#W6sZmlsZQ%3D%3D?line=40'>41</a>\u001b[0m         client_ids\u001b[39m=\u001b[39mtrain_data_paths,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/kiliansprenkamp/Desktop/code/refugee_supervised_text_classification/src/multi_class_text_classifier/tensorflow/FL_BERT.ipynb#W6sZmlsZQ%3D%3D?line=41'>42</a>\u001b[0m         create_tf_dataset_for_client_fn\u001b[39m=\u001b[39mcreate_tf_dataset_for_client_fn\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/kiliansprenkamp/Desktop/code/refugee_supervised_text_classification/src/multi_class_text_classifier/tensorflow/FL_BERT.ipynb#W6sZmlsZQ%3D%3D?line=42'>43</a>\u001b[0m     )\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/kiliansprenkamp/Desktop/code/refugee_supervised_text_classification/src/multi_class_text_classifier/tensorflow/FL_BERT.ipynb#W6sZmlsZQ%3D%3D?line=44'>45</a>\u001b[0m test_data \u001b[39m=\u001b[39m tff\u001b[39m.\u001b[39msimulation\u001b[39m.\u001b[39mdatasets\u001b[39m.\u001b[39mClientData\u001b[39m.\u001b[39mfrom_clients_and_fn(\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/kiliansprenkamp/Desktop/code/refugee_supervised_text_classification/src/multi_class_text_classifier/tensorflow/FL_BERT.ipynb#W6sZmlsZQ%3D%3D?line=45'>46</a>\u001b[0m         client_ids\u001b[39m=\u001b[39mtest_data_paths,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/kiliansprenkamp/Desktop/code/refugee_supervised_text_classification/src/multi_class_text_classifier/tensorflow/FL_BERT.ipynb#W6sZmlsZQ%3D%3D?line=46'>47</a>\u001b[0m         create_tf_dataset_for_client_fn\u001b[39m=\u001b[39mcreate_tf_dataset_for_client_fn\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/kiliansprenkamp/Desktop/code/refugee_supervised_text_classification/src/multi_class_text_classifier/tensorflow/FL_BERT.ipynb#W6sZmlsZQ%3D%3D?line=47'>48</a>\u001b[0m     )\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/kiliansprenkamp/Desktop/code/refugee_supervised_text_classification/src/multi_class_text_classifier/tensorflow/FL_BERT.ipynb#W6sZmlsZQ%3D%3D?line=49'>50</a>\u001b[0m example_dataset \u001b[39m=\u001b[39m train_data\u001b[39m.\u001b[39mcreate_tf_dataset_for_client(\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/kiliansprenkamp/Desktop/code/refugee_supervised_text_classification/src/multi_class_text_classifier/tensorflow/FL_BERT.ipynb#W6sZmlsZQ%3D%3D?line=50'>51</a>\u001b[0m         train_data\u001b[39m.\u001b[39mclient_ids[\u001b[39m0\u001b[39m]\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/kiliansprenkamp/Desktop/code/refugee_supervised_text_classification/src/multi_class_text_classifier/tensorflow/FL_BERT.ipynb#W6sZmlsZQ%3D%3D?line=51'>52</a>\u001b[0m     )\n",
      "\u001b[0;31mNameError\u001b[0m: name 'tff' is not defined"
     ]
    }
   ],
   "source": [
    "#GET-DATASETS\n",
    "from glob import glob\n",
    "from random import sample\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import collections\n",
    "# PREFETCH_BUFFER = 512\n",
    "# BATCH_SIZE = 512\n",
    "# NUM_EPOCHS = 10\n",
    "PREFETCH_BUFFER = 1024\n",
    "BATCH_SIZE = 1024\n",
    "NUM_EPOCHS = 5\n",
    "\n",
    "df = pd.read_csv(\"../../../data/df_testing.csv\")\n",
    "# train_data_paths =glob('.')\n",
    "# test_data_paths = glob('/scratch/users/jodelgado/classifier_forecaster/forecasting_classifier_privacy/Dataset/*/test/*/scaled/')\n",
    "\n",
    "\n",
    "\n",
    "# train_data_paths = get_sample(train_data_paths)\n",
    "# test_data_paths = get_sample(test_data_paths)\n",
    "\n",
    "def create_tf_dataset_for_client_fn(df, federation_level): # path is name of country the 'federator'\n",
    "    def batch_format_fn(element):\n",
    "        return collections.OrderedDict(\n",
    "            x=element['x'],\n",
    "            y=element['y'],)\n",
    "    \n",
    "    df = df[df[\"federation_level\"]==federation_level]\n",
    "\n",
    "    data_x = df.x.values\n",
    "    data_y = df.y.values\n",
    "\n",
    "    data = collections.OrderedDict((('y', data_y), ('x', data_x)))\n",
    "    dataset = tf.data.Dataset.from_tensor_slices(data)\n",
    "    return dataset.repeat(NUM_EPOCHS).batch(BATCH_SIZE).map(batch_format_fn).prefetch(PREFETCH_BUFFER)\n",
    "\n",
    "df_tf_sim =create_tf_dataset_for_client_fn(df, \"germany\")\n",
    "\n",
    "train_data = tff.simulation.datasets.ClientData.from_clients_and_fn(\n",
    "        client_ids=train_data_paths,\n",
    "        create_tf_dataset_for_client_fn=create_tf_dataset_for_client_fn\n",
    "    )\n",
    "\n",
    "test_data = tff.simulation.datasets.ClientData.from_clients_and_fn(\n",
    "        client_ids=test_data_paths,\n",
    "        create_tf_dataset_for_client_fn=create_tf_dataset_for_client_fn\n",
    "    )\n",
    "\n",
    "example_dataset = train_data.create_tf_dataset_for_client(\n",
    "        train_data.client_ids[0]\n",
    "    )\n",
    "\n",
    "eval_dataset = get_eval_dataset()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "95b6d739",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<PrefetchDataset element_spec=OrderedDict([('x', TensorSpec(shape=(None,), dtype=tf.string, name=None)), ('y', TensorSpec(shape=(None,), dtype=tf.int64, name=None))])>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tf_sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "79cef1ba-531f-4d33-a8d9-f8e900f6b61e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_iterative_process(noise,n_clients=0):\n",
    "    if noise == 0.0:\n",
    "        iterative_process = tff.learning.build_federated_averaging_process(\n",
    "            model_tff,\n",
    "            client_optimizer_fn=lambda: keras.optimizers.Adam(),\n",
    "            server_optimizer_fn=lambda: keras.optimizers.SGD(learning_rate=1),\n",
    "            use_experimental_simulation_loop=True)\n",
    "    else:\n",
    "        aggregation_factory = tff.learning.model_update_aggregator.dp_aggregator(noise, n_clients)\n",
    "        iterative_process = tff.learning.build_federated_averaging_process(\n",
    "            model_tff,\n",
    "            client_optimizer_fn=lambda: keras.optimizers.Adam(),\n",
    "            server_optimizer_fn=lambda: keras.optimizers.SGD(learning_rate=1),\n",
    "            model_update_aggregation_factory=aggregation_factory,\n",
    "            use_experimental_simulation_loop=True)\n",
    "    \n",
    "    return iterative_process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "81d0d022",
   "metadata": {},
   "outputs": [],
   "source": [
    "def base_model():\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(100,return_sequences=False,input_shape=(24,1)))\n",
    "    model.add(Dense(24))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1e2ec0f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_tff():\n",
    "    model = base_model()\n",
    "    return tff.learning.from_keras_model(\n",
    "      model,\n",
    "      input_spec=train_data.element_type_structure,\n",
    "      loss=keras.losses.MeanSquaredError(),\n",
    "      metrics=[\n",
    "            MeanAbsoluteError(), MeanSquaredError(), RootMeanSquaredError(),\n",
    "                                    MeanAbsolutePercentageError() \n",
    "              ])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "42e84278-6ab2-452c-97cc-1e1efe4a8bec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_all(results,state,n_rounds,config,unique_id):\n",
    "    results.reset_index(inplace=True,drop=True)\n",
    "\n",
    "    centralized_model = from_federated_to_keras(state=state)\n",
    "    path = f'/scratch/users/jodelgado/classifier_forecaster/forecasting_classifier_privacy/Federated_Learning/results/experiments/1000_rounds/{unique_id}/{n_rounds}/'\n",
    "\n",
    "    config['round'] = n_rounds\n",
    "    \n",
    "\n",
    "    if not os.path.exists(path):\n",
    "        print(f'Saving in {path}')\n",
    "        os.makedirs(path)\n",
    "        pd.DataFrame(config,index=[0]).to_csv(f'{path}config.csv')\n",
    "        get_model_in_text(path,base_model)\n",
    "        results.to_csv(f'{path}results.csv')\n",
    "        centralized_model.save(f'{path}model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ad9eee63",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_clients = len(train_data_paths)\n",
    "n_clients = 70\n",
    "Noise = 0.48\n",
    "Q = n_clients/total_clients\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c2ab1031",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {'Q':Q,\n",
    "          'clients_per_round':int(n_clients),\n",
    "          'total_clients':len(train_data_paths),\n",
    "          'noise': Noise,\n",
    "          'batch_size':int(BATCH_SIZE),\n",
    "          'eval_client_size':len(glob('../Dataset/*/test/*/scaled/')),\n",
    "          'internal_epochs':int(NUM_EPOCHS)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "26c93173",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Q': 0.2028985507246377, 'clients_per_round': 70, 'total_clients': 345, 'noise': 0.48, 'batch_size': 1024, 'eval_client_size': 890, 'internal_epochs': 5}\n"
     ]
    }
   ],
   "source": [
    "print(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "be9e876a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tff.backends.native.set_local_execution_context(clients_per_thread=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d661ae53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    }
   ],
   "source": [
    "iterative_process = get_iterative_process(Noise,n_clients)\n",
    "evaluation = tff.learning.build_federated_evaluation(model_tff,use_experimental_simulation_loop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "de01c73d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/users/jodelgado/.local/lib/python3.8/site-packages/tensorflow_federated/python/core/impl/compiler/tensorflow_computation_transformations.py:59: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.compat.v1.graph_util.extract_sub_graph`\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/users/jodelgado/.local/lib/python3.8/site-packages/tensorflow_federated/python/core/impl/compiler/tensorflow_computation_transformations.py:59: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.compat.v1.graph_util.extract_sub_graph`\n",
      "2023-04-18 16:55:58.616773: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:176] None of the MLIR Optimization Passes are enabled (registered 2)\n",
      "2023-04-18 16:55:58.628652: I tensorflow/core/platform/profile_utils/cpu_utils.cc:114] CPU Frequency: 2600000000 Hz\n"
     ]
    }
   ],
   "source": [
    "nest_asyncio.apply()\n",
    "state = iterative_process.initialize()  \n",
    "NUM_ROUNDS = 125\n",
    "results = pd.DataFrame()\n",
    "unique_id = str(uuid.uuid4())[0:8]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c6355f6b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/124 [00:00<?, ?it/s]2023-04-18 16:59:52.451641: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublas.so.11\n",
      "2023-04-18 16:59:52.899884: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublasLt.so.11\n",
      " 19%|█▉        | 24/124 [55:26<3:23:05, 121.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('zeroing_norm', (_GlobalState(current_estimate=3.1622777, target_quantile=0.98, learning_rate=2.3025851, below_estimate_state=()), ())), ('inner_agg', (_GlobalState(numerator_state=_GlobalState(noise_multiplier=0.48113248, sum_state=_GlobalState(l2_norm_clip=0.4943598, stddev=0.23785256), quantile_estimator_state=_GlobalState(current_estimate=0.4943598, target_quantile=0.5, learning_rate=0.2, below_estimate_state=_GlobalState(numerator_state=_GlobalState(l2_norm_clip=0.5, stddev=3.5), denominator=70.0))), denominator=70.0), ())), ('zeroed_count_agg', ())])\n",
      "Train:55.05063247680664\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-18 17:53:42.278568: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudnn.so.8\n",
      "2023-04-18 17:53:43.475120: I tensorflow/stream_executor/cuda/cuda_dnn.cc:359] Loaded cuDNN version 8004\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8453/8453 [==============================] - 27s 3ms/step - loss: 2.9891e-04 - mean_absolute_error: 0.0099 - mean_squared_error: 2.9891e-04 - root_mean_squared_error: 0.0173 - mean_absolute_percentage_error: 69.8990\n",
      "Saving in /scratch/users/jodelgado/classifier_forecaster/forecasting_classifier_privacy/Federated_Learning/results/experiments/1000_rounds/4ffbd676/25/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-18 17:54:10.968084: W tensorflow/python/util/util.cc:348] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n",
      "WARNING:absl:Found untraced functions such as lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /scratch/users/jodelgado/classifier_forecaster/forecasting_classifier_privacy/Federated_Learning/results/experiments/1000_rounds/4ffbd676/25/model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /scratch/users/jodelgado/classifier_forecaster/forecasting_classifier_privacy/Federated_Learning/results/experiments/1000_rounds/4ffbd676/25/model/assets\n",
      " 40%|███▉      | 49/124 [1:49:45<2:43:59, 131.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('zeroing_norm', (_GlobalState(current_estimate=1.0000002, target_quantile=0.98, learning_rate=2.3025851, below_estimate_state=()), ())), ('inner_agg', (_GlobalState(numerator_state=_GlobalState(noise_multiplier=0.48113248, sum_state=_GlobalState(l2_norm_clip=0.35064292, stddev=0.1687057), quantile_estimator_state=_GlobalState(current_estimate=0.35064292, target_quantile=0.5, learning_rate=0.2, below_estimate_state=_GlobalState(numerator_state=_GlobalState(l2_norm_clip=0.5, stddev=3.5), denominator=70.0))), denominator=70.0), ())), ('zeroed_count_agg', ())])\n",
      "Train:34.69533920288086\n",
      "8453/8453 [==============================] - 24s 3ms/step - loss: 2.1761e-04 - mean_absolute_error: 0.0082 - mean_squared_error: 2.1761e-04 - root_mean_squared_error: 0.0148 - mean_absolute_percentage_error: 55.4479\n",
      "Saving in /scratch/users/jodelgado/classifier_forecaster/forecasting_classifier_privacy/Federated_Learning/results/experiments/1000_rounds/4ffbd676/50/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_4_layer_call_and_return_conditional_losses, lstm_cell_4_layer_call_fn, lstm_cell_4_layer_call_fn, lstm_cell_4_layer_call_and_return_conditional_losses, lstm_cell_4_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /scratch/users/jodelgado/classifier_forecaster/forecasting_classifier_privacy/Federated_Learning/results/experiments/1000_rounds/4ffbd676/50/model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /scratch/users/jodelgado/classifier_forecaster/forecasting_classifier_privacy/Federated_Learning/results/experiments/1000_rounds/4ffbd676/50/model/assets\n",
      " 60%|█████▉    | 74/124 [2:43:16<1:40:51, 121.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('zeroing_norm', (_GlobalState(current_estimate=0.31622788, target_quantile=0.98, learning_rate=2.3025851, below_estimate_state=()), ())), ('inner_agg', (_GlobalState(numerator_state=_GlobalState(noise_multiplier=0.48113248, sum_state=_GlobalState(l2_norm_clip=0.30729866, stddev=0.14785136), quantile_estimator_state=_GlobalState(current_estimate=0.30729866, target_quantile=0.5, learning_rate=0.2, below_estimate_state=_GlobalState(numerator_state=_GlobalState(l2_norm_clip=0.5, stddev=3.5), denominator=70.0))), denominator=70.0), ())), ('zeroed_count_agg', ())])\n",
      "Train:33.979881286621094\n",
      "8453/8453 [==============================] - 24s 3ms/step - loss: 1.8656e-04 - mean_absolute_error: 0.0077 - mean_squared_error: 1.8656e-04 - root_mean_squared_error: 0.0137 - mean_absolute_percentage_error: 56.7749\n",
      "Saving in /scratch/users/jodelgado/classifier_forecaster/forecasting_classifier_privacy/Federated_Learning/results/experiments/1000_rounds/4ffbd676/75/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_7_layer_call_and_return_conditional_losses, lstm_cell_7_layer_call_fn, lstm_cell_7_layer_call_fn, lstm_cell_7_layer_call_and_return_conditional_losses, lstm_cell_7_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /scratch/users/jodelgado/classifier_forecaster/forecasting_classifier_privacy/Federated_Learning/results/experiments/1000_rounds/4ffbd676/75/model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /scratch/users/jodelgado/classifier_forecaster/forecasting_classifier_privacy/Federated_Learning/results/experiments/1000_rounds/4ffbd676/75/model/assets\n",
      " 80%|███████▉  | 99/124 [3:37:37<53:38, 128.73s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('zeroing_norm', (_GlobalState(current_estimate=0.100000046, target_quantile=0.98, learning_rate=2.3025851, below_estimate_state=()), ())), ('inner_agg', (_GlobalState(numerator_state=_GlobalState(noise_multiplier=0.48113248, sum_state=_GlobalState(l2_norm_clip=0.25863373, stddev=0.12443709), quantile_estimator_state=_GlobalState(current_estimate=0.25863373, target_quantile=0.5, learning_rate=0.2, below_estimate_state=_GlobalState(numerator_state=_GlobalState(l2_norm_clip=0.5, stddev=3.5), denominator=70.0))), denominator=70.0), ())), ('zeroed_count_agg', ())])\n",
      "Train:34.83448028564453\n",
      "8453/8453 [==============================] - 24s 3ms/step - loss: 1.5793e-04 - mean_absolute_error: 0.0067 - mean_squared_error: 1.5793e-04 - root_mean_squared_error: 0.0126 - mean_absolute_percentage_error: 45.2697\n",
      "Saving in /scratch/users/jodelgado/classifier_forecaster/forecasting_classifier_privacy/Federated_Learning/results/experiments/1000_rounds/4ffbd676/100/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_10_layer_call_and_return_conditional_losses, lstm_cell_10_layer_call_fn, lstm_cell_10_layer_call_fn, lstm_cell_10_layer_call_and_return_conditional_losses, lstm_cell_10_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /scratch/users/jodelgado/classifier_forecaster/forecasting_classifier_privacy/Federated_Learning/results/experiments/1000_rounds/4ffbd676/100/model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /scratch/users/jodelgado/classifier_forecaster/forecasting_classifier_privacy/Federated_Learning/results/experiments/1000_rounds/4ffbd676/100/model/assets\n",
      "100%|██████████| 124/124 [4:32:03<00:00, 129.64s/it]\n"
     ]
    }
   ],
   "source": [
    "t = trange(1,NUM_ROUNDS, desc='', leave=True)\n",
    "        \n",
    "for round_num in t:\n",
    "    \n",
    "\n",
    "    start = time()\n",
    "    \n",
    "    train_set = get_training_Q(Q)\n",
    "\n",
    "    state, metrics = iterative_process.next(state, train_set)\n",
    "    \n",
    "    if round_num % 25 == 0:\n",
    "        metrics['train']['round_number'] = int(round_num)\n",
    "        metrics['train']['time'] = time()-start\n",
    "        metrics_train_df = pd.DataFrame(metrics['train'],index=[0])\n",
    "        sys.stdout.flush()\n",
    "        \n",
    "        if Noise != 0.0:\n",
    "            print(state.delta_aggregate_state)\n",
    "\n",
    "        print(f'Train:{metrics_train_df[\"mean_absolute_percentage_error\"].iloc[0]}')\n",
    "        \n",
    "        metrics_test_df = evaluate_federated_model(state)\n",
    "        metrics_test_df['round_number']= round_num\n",
    "        metrics_train_df = metrics_train_df.merge(metrics_test_df, on='round_number', suffixes=('_train','_test'))\n",
    "        results = pd.concat([results,metrics_train_df])\n",
    "       \n",
    "        save_all(results=results,state= state,n_rounds=round_num,config=config,unique_id=unique_id)\n",
    "       \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9d4af1e5-8450-49ed-99bc-674c8355e775",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  MAPE = 25.108067\n",
    "# Q\t0.005794\n",
    "# clients_per_round\t10\n",
    "# total_clients\t1726\n",
    "# noise\t0.10\n",
    "# batch_size\t512\n",
    "# internal_epochs\t10\n",
    "# Optimizer ADAM\n",
    "# 100 rounds "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "674ea1cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_absolute_error_train</th>\n",
       "      <th>mean_squared_error_train</th>\n",
       "      <th>root_mean_squared_error_train</th>\n",
       "      <th>mean_absolute_percentage_error_train</th>\n",
       "      <th>loss_train</th>\n",
       "      <th>round_number</th>\n",
       "      <th>time</th>\n",
       "      <th>loss_test</th>\n",
       "      <th>mean_absolute_error_test</th>\n",
       "      <th>mean_squared_error_test</th>\n",
       "      <th>root_mean_squared_error_test</th>\n",
       "      <th>mean_absolute_percentage_error_test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.006792</td>\n",
       "      <td>0.000192</td>\n",
       "      <td>0.013864</td>\n",
       "      <td>55.050632</td>\n",
       "      <td>0.000192</td>\n",
       "      <td>25</td>\n",
       "      <td>132.741692</td>\n",
       "      <td>0.000299</td>\n",
       "      <td>0.009923</td>\n",
       "      <td>0.000299</td>\n",
       "      <td>0.017289</td>\n",
       "      <td>69.899033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.005065</td>\n",
       "      <td>0.000095</td>\n",
       "      <td>0.009732</td>\n",
       "      <td>34.695339</td>\n",
       "      <td>0.000095</td>\n",
       "      <td>50</td>\n",
       "      <td>124.682097</td>\n",
       "      <td>0.000218</td>\n",
       "      <td>0.008156</td>\n",
       "      <td>0.000218</td>\n",
       "      <td>0.014752</td>\n",
       "      <td>55.447880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.005063</td>\n",
       "      <td>0.000090</td>\n",
       "      <td>0.009490</td>\n",
       "      <td>33.979881</td>\n",
       "      <td>0.000090</td>\n",
       "      <td>75</td>\n",
       "      <td>121.416200</td>\n",
       "      <td>0.000187</td>\n",
       "      <td>0.007681</td>\n",
       "      <td>0.000187</td>\n",
       "      <td>0.013659</td>\n",
       "      <td>56.774860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.004827</td>\n",
       "      <td>0.000083</td>\n",
       "      <td>0.009105</td>\n",
       "      <td>34.834480</td>\n",
       "      <td>0.000083</td>\n",
       "      <td>100</td>\n",
       "      <td>120.216939</td>\n",
       "      <td>0.000158</td>\n",
       "      <td>0.006653</td>\n",
       "      <td>0.000158</td>\n",
       "      <td>0.012567</td>\n",
       "      <td>45.269745</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_absolute_error_train  mean_squared_error_train  \\\n",
       "0                   0.006792                  0.000192   \n",
       "1                   0.005065                  0.000095   \n",
       "2                   0.005063                  0.000090   \n",
       "3                   0.004827                  0.000083   \n",
       "\n",
       "   root_mean_squared_error_train  mean_absolute_percentage_error_train  \\\n",
       "0                       0.013864                             55.050632   \n",
       "1                       0.009732                             34.695339   \n",
       "2                       0.009490                             33.979881   \n",
       "3                       0.009105                             34.834480   \n",
       "\n",
       "   loss_train  round_number        time  loss_test  mean_absolute_error_test  \\\n",
       "0    0.000192            25  132.741692   0.000299                  0.009923   \n",
       "1    0.000095            50  124.682097   0.000218                  0.008156   \n",
       "2    0.000090            75  121.416200   0.000187                  0.007681   \n",
       "3    0.000083           100  120.216939   0.000158                  0.006653   \n",
       "\n",
       "   mean_squared_error_test  root_mean_squared_error_test  \\\n",
       "0                 0.000299                      0.017289   \n",
       "1                 0.000218                      0.014752   \n",
       "2                 0.000187                      0.013659   \n",
       "3                 0.000158                      0.012567   \n",
       "\n",
       "   mean_absolute_percentage_error_test  \n",
       "0                            69.899033  \n",
       "1                            55.447880  \n",
       "2                            56.774860  \n",
       "3                            45.269745  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fd09959",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "refugeeAnalysis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
