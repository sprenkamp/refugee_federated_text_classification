{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9ab8274a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-23 09:55:02.377447: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-05-23 09:55:03.163947: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import tensorflow_federated as tff\n",
    "import tensorflow as tf\n",
    "import tensorflow_text as text\n",
    "import collections\n",
    "from IPython.display import display\n",
    "from tensorflow import keras\n",
    "import pandas as pd\n",
    "from random import sample\n",
    "import numpy as np\n",
    "# import seaborn as sns\n",
    "import os\n",
    "from tqdm import trange\n",
    "from random import sample\n",
    "from glob import glob\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.layers import MaxPooling2D\n",
    "from tensorflow.keras.layers import Activation\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Dense,LSTM,Dropout,Embedding\n",
    "from tensorflow.compat.v1.keras.layers import CuDNNLSTM\n",
    "# import tensorflow_text as text\n",
    "import tensorflow_hub as hub\n",
    "# from tensorflow.keras.losses import MeanAbsoluteError,MeanSquaredError,RootMeanSquaredError,MeanAbsolutePercentageError\n",
    "# from tensorflow.keras.metrics import MeanAbsoluteError,MeanSquaredError,RootMeanSquaredError,MeanAbsolutePercentageError\n",
    "import nest_asyncio\n",
    "from time import time\n",
    "import sys\n",
    "\n",
    "import uuid\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dd90d214",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1 GPU(s) available.\n",
      "GPU 0: Tesla T4\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device_count = torch.cuda.device_count()\n",
    "    print(f\"Found {device_count} GPU(s) available.\")\n",
    "    for i in range(device_count):\n",
    "        device_name = torch.cuda.get_device_name(i)\n",
    "        print(f\"GPU {i}: {device_name}\")\n",
    "else:\n",
    "    print(\"No GPUs available.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a4da45ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-23 09:55:07.250171: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-05-23 09:55:07.253195: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-05-23 09:55:07.255185: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.config.list_physical_devices('GPU')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5a5f1360",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_training_Q(Q):\n",
    "    size = int(Q*len(train_data.client_ids))\n",
    "    sampled_clients = np.random.choice(\n",
    "            train_data.client_ids,\n",
    "            size=size,\n",
    "            replace=False)\n",
    "    \n",
    "    sampled_train_data = [\n",
    "            train_data.create_tf_dataset_for_client(client)\n",
    "            for client in sampled_clients\n",
    "        ]\n",
    "    \n",
    "    return sampled_train_data\n",
    "\n",
    "def get_test_Q(Q):\n",
    "    size = int(Q*len(test_data.client_ids))\n",
    "    sampled_clients = np.random.choice(\n",
    "            test_data.client_ids,\n",
    "            size=size,\n",
    "            replace=False)\n",
    "    \n",
    "    ids = [_id.split('/')[-3] for _id in sampled_clients]\n",
    "    print(ids)\n",
    "    \n",
    "    sampled_test_data = [\n",
    "            test_data.create_tf_dataset_for_client(client)\n",
    "            for client in sampled_clients\n",
    "        ]\n",
    "    return sampled_test_data\n",
    "\n",
    "def get_eval_dataset():\n",
    "    test_data_paths = glob('../Dataset/*/test/*/scaled/')\n",
    "    \n",
    "    dataset_test= []\n",
    "    for path in test_data_paths:\n",
    "        \n",
    "        d = dict(X= np.load(f'{path}data_X.npy'),\n",
    "                 y= np.load(f'{path}data_Y.npy'))    \n",
    "        dataset_test.append(d)\n",
    "        \n",
    "    dataset = {}\n",
    "    \n",
    "    dataset['X_test'] = np.concatenate([data['X'] for data in dataset_test],axis=0)\n",
    "    dataset['y_test'] = np.concatenate([data['y'] for data in dataset_test],axis=0)\n",
    "    \n",
    "    return dataset\n",
    "\n",
    "def evaluate_model(model):\n",
    "    X_test= eval_dataset['X_test']\n",
    "    y_test = eval_dataset['y_test']\n",
    "    \n",
    "    ev = model.evaluate(x=X_test,y=y_test,batch_size=2048,return_dict=True)\n",
    "    result  = pd.DataFrame(ev,index=[0])\n",
    "    return result\n",
    "\n",
    "def from_federated_to_keras(state):\n",
    "    federated_model = base_model()\n",
    "    federated_model.compile(optimizer=tf.keras.optimizers.SGD(learning_rate=1.0),\n",
    "                            loss=tf.keras.losses.MeanSquaredError(),\n",
    "                            metrics=[MeanAbsoluteError(), MeanSquaredError(), RootMeanSquaredError(),\n",
    "                                    MeanAbsolutePercentageError() \n",
    "                                    ])\n",
    "    state.model.assign_weights_to(model=federated_model)\n",
    "    return federated_model\n",
    "    \n",
    "def evaluate_federated_model(state):\n",
    "    federated_model = from_federated_to_keras(state)\n",
    "\n",
    "    return evaluate_model(federated_model)\n",
    "\n",
    "def get_model_in_text(path,model_fn):\n",
    "    m = model_fn()\n",
    "    with open(f'{path}model_report.txt','w') as fh:\n",
    "        m.summary(print_fn=lambda x: fh.write(x + '\\n'))\n",
    "\n",
    "def save_all(results,state,n_rounds,config,unique_id):\n",
    "    results.reset_index(inplace=True,drop=True)\n",
    "\n",
    "    centralized_model = from_federated_to_keras(state=state)\n",
    "    path = f'/scratch/users/jodelgado/classifier_forecaster/forecasting_classifier_privacy/Federated_Learning/results/experiments/1000_rounds/{unique_id}/{n_rounds}/'\n",
    "\n",
    "    config['round'] = n_rounds\n",
    "    \n",
    "\n",
    "    if not os.path.exists(path):\n",
    "        print(f'Saving in {path}')\n",
    "        os.makedirs(path)\n",
    "        pd.DataFrame(config,index=[0]).to_csv(f'{path}config.csv')\n",
    "        get_model_in_text(path,base_model)\n",
    "        results.to_csv(f'{path}results.csv')\n",
    "        centralized_model.save(f'{path}model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "06c05641",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/federated/venv/lib/python3.9/site-packages/tensorflow/python/data/ops/structured_function.py:254: UserWarning: Even though the `tf.config.experimental_run_functions_eagerly` option is set, this option does not apply to tf.data functions. To force eager execution of tf.data functions, please use `tf.data.experimental.enable_debug_mode()`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#GET-DATASETS\n",
    "from glob import glob\n",
    "from random import sample\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import collections\n",
    "from tensorflow_privacy.privacy.optimizers.dp_optimizer import DPAdamGaussianOptimizer\n",
    "tf.config.run_functions_eagerly(True)\n",
    "\n",
    "\n",
    "# from transformers import BertTokenizer\n",
    "# tokenizer = BertTokenizer.from_pretrained('bert-base-cased')  # load pretrained tokenizer model\n",
    "\n",
    "# PREFETCH_BUFFER = 512\n",
    "# BATCH_SIZE = 512\n",
    "# NUM_EPOCHS = 10\n",
    "PREFETCH_BUFFER = 1024\n",
    "BATCH_SIZE = 4\n",
    "NUM_EPOCHS = 5\n",
    "\n",
    "df = pd.read_csv(\"../../../models/firstTry/df_testing.csv\").sample(1000)\n",
    "tokens = set()\n",
    "for message in df[\"x\"]:\n",
    "    text_tokens = message.split()  # Split text into tokens based on spaces or other delimiters\n",
    "    tokens.update(text_tokens)\n",
    "\n",
    "_VOCAB = list(set(tokens))\n",
    "\n",
    "_VOCAB_SIZE = len(_VOCAB)\n",
    "\n",
    "lookup_table = tf.lookup.StaticVocabularyTable(\n",
    "    tf.lookup.KeyValueTensorInitializer(\n",
    "        keys=_VOCAB,\n",
    "        key_dtype=tf.string,\n",
    "        values=tf.range(tf.size(_VOCAB, out_type=tf.int64), dtype=tf.int64),\n",
    "        value_dtype=tf.int64\n",
    "    ),\n",
    "    num_oov_buckets=1\n",
    ")\n",
    "\n",
    "tokenizer = text.BertTokenizer(lookup_table, token_out_type=tf.string)\n",
    "\n",
    "text_tokens = tokenizer.tokenize(df[\"x\"])\n",
    "\n",
    "def create_tf_dataset_for_client_fn(federation_level):\n",
    "    max_length = 512\n",
    "\n",
    "    def tokenize_map_fn(data):\n",
    "        tokenized_inputs = tokenizer.tokenize(data['x'])\n",
    "        input_ids = lookup_table.lookup(tokenized_inputs)\n",
    "        input_ids = input_ids.to_tensor()\n",
    "        return collections.OrderedDict(x=input_ids, y=data[\"y\"])\n",
    "\n",
    "    # def tf_tokenize_map_fn(data):\n",
    "    #     # print(data)\n",
    "    #     input_ids, label = tokenize_map_fn(data['x'], data[\"y\"])\n",
    "    #     # input_ids.set_shape([None])\n",
    "    #     # label.set_shape([])\n",
    "    #     return \n",
    "\n",
    "    df_client = df[df[\"federation_level\"] == federation_level]\n",
    "    data_x = df_client.x.values\n",
    "    data_y = df_client.y.values\n",
    "    data = collections.OrderedDict((('y', data_y), ('x', data_x)))\n",
    "    dataset = tf.data.Dataset.from_tensor_slices(data)\n",
    "    # print(dataset)\n",
    "    dataset = dataset.map(tokenize_map_fn)\n",
    "    \n",
    "    # ordered_dict_dataset = dataset.map(lambda x: collections.OrderedDict([('x', x['input_ids']), ('y', x['label'])]))\n",
    "\n",
    "    return dataset.repeat(NUM_EPOCHS).batch(BATCH_SIZE).prefetch(PREFETCH_BUFFER)\n",
    "\n",
    "\n",
    "train_data = tff.simulation.datasets.ClientData.from_clients_and_tf_fn(\n",
    "        client_ids=df.federation_level.unique().tolist(),\n",
    "        serializable_dataset_fn=create_tf_dataset_for_client_fn\n",
    "    )\n",
    "\n",
    "test_data = tff.simulation.datasets.ClientData.from_clients_and_tf_fn(\n",
    "        client_ids=df.federation_level.unique().tolist(),\n",
    "        serializable_dataset_fn=create_tf_dataset_for_client_fn\n",
    "    )\n",
    "\n",
    "example_dataset = train_data.create_tf_dataset_for_client(\n",
    "        train_data.client_ids[0]\n",
    "    )\n",
    "\n",
    "train_data = [train_data.create_tf_dataset_for_client(client_id) for client_id in train_data.client_ids]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "27a5e677",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('x',\n",
       "              TensorSpec(shape=(None, None, None, None), dtype=tf.int64, name=None)),\n",
       "             ('y', TensorSpec(shape=(None,), dtype=tf.int64, name=None))])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[0].element_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d7cdffb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_federated as tff\n",
    "# from transformers import TFBertModel, BertTokenizer\n",
    "from tensorflow.keras.layers import Dropout, Dense, Input\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "# from tensorflow.keras.losses import MeanSquaredError\n",
    "# from tensorflow.keras.metrics import MeanAbsoluteError, MeanSquaredError, RootMeanSquaredError, MeanAbsolutePercentageError\n",
    "\n",
    "class BertTextClassifier(tf.keras.Model):\n",
    "    def __init__(self, num_labels, vocab_size, embedding_dim, dropout=0.5):\n",
    "        super(BertTextClassifier, self).__init__()\n",
    "        self.embedding = Embedding(vocab_size, embedding_dim, input_length=512)\n",
    "        self.dropout = Dropout(dropout)\n",
    "        self.dense = Dense(768, activation='relu')\n",
    "        self.final_dense = Dense(num_labels, activation='softmax')\n",
    "\n",
    "    def call(self, inputs):\n",
    "        # print(inputs)\n",
    "        embedded_input = self.embedding(inputs)  # Update the key to \"input_ids\"\n",
    "        pooled_output = tf.reduce_mean(embedded_input, axis=1)\n",
    "        dropout_output = self.dropout(pooled_output)\n",
    "        dense_output = self.dense(dropout_output)\n",
    "        final_output = self.final_dense(dense_output)\n",
    "        return final_output\n",
    "\n",
    "\n",
    "\n",
    "def model_tff():\n",
    "    model = BertTextClassifier(num_labels=len(df.y.unique()), vocab_size=_VOCAB_SIZE, embedding_dim=256)  # Replace your_num_labels with the actual number of labels\n",
    "    return tff.learning.models.from_keras_model(\n",
    "      model,\n",
    "      input_spec=train_data[0].element_spec,\n",
    "      loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "      metrics=[tf.keras.metrics.SparseCategoricalAccuracy()])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "19b98ad9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-23 10:12:49.657544: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/StatefulPartitionedCall_grad/StatefulPartitionedCall_1' with dtype float and shape [?,10]\n",
      "\t [[{{node gradients/StatefulPartitionedCall_grad/StatefulPartitionedCall_1}}]]\n",
      "2023-05-23 10:12:49.657653: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/StatefulPartitionedCall_grad/StatefulPartitionedCall_4' with dtype float and shape [?,?,?,768]\n",
      "\t [[{{node gradients/StatefulPartitionedCall_grad/StatefulPartitionedCall_4}}]]\n",
      "2023-05-23 10:12:49.657704: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/StatefulPartitionedCall_grad/StatefulPartitionedCall_5' with dtype int32 and shape [4]\n",
      "\t [[{{node gradients/StatefulPartitionedCall_grad/StatefulPartitionedCall_5}}]]\n",
      "2023-05-23 10:12:49.657752: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/StatefulPartitionedCall_grad/StatefulPartitionedCall_7' with dtype float and shape [?,768]\n",
      "\t [[{{node gradients/StatefulPartitionedCall_grad/StatefulPartitionedCall_7}}]]\n",
      "2023-05-23 10:12:49.657800: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/StatefulPartitionedCall_grad/StatefulPartitionedCall_10' with dtype float and shape [?,?,?,256]\n",
      "\t [[{{node gradients/StatefulPartitionedCall_grad/StatefulPartitionedCall_10}}]]\n",
      "2023-05-23 10:12:49.657848: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/StatefulPartitionedCall_grad/StatefulPartitionedCall_11' with dtype int32 and shape [4]\n",
      "\t [[{{node gradients/StatefulPartitionedCall_grad/StatefulPartitionedCall_11}}]]\n",
      "2023-05-23 10:12:49.657894: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/StatefulPartitionedCall_grad/StatefulPartitionedCall_13' with dtype float and shape [?,?,?,256]\n",
      "\t [[{{node gradients/StatefulPartitionedCall_grad/StatefulPartitionedCall_13}}]]\n",
      "2023-05-23 10:12:49.657940: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/StatefulPartitionedCall_grad/StatefulPartitionedCall_14' with dtype float and shape [?,?,?,256]\n",
      "\t [[{{node gradients/StatefulPartitionedCall_grad/StatefulPartitionedCall_14}}]]\n",
      "2023-05-23 10:12:49.657987: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/StatefulPartitionedCall_grad/StatefulPartitionedCall_15' with dtype float and shape [?,?,?,256]\n",
      "\t [[{{node gradients/StatefulPartitionedCall_grad/StatefulPartitionedCall_15}}]]\n",
      "2023-05-23 10:12:49.658034: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/StatefulPartitionedCall_grad/StatefulPartitionedCall_16' with dtype float\n",
      "\t [[{{node gradients/StatefulPartitionedCall_grad/StatefulPartitionedCall_16}}]]\n",
      "2023-05-23 10:12:49.658095: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/StatefulPartitionedCall_grad/StatefulPartitionedCall_17' with dtype float and shape [?,?,?,?,256]\n",
      "\t [[{{node gradients/StatefulPartitionedCall_grad/StatefulPartitionedCall_17}}]]\n",
      "2023-05-23 10:12:49.658152: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/StatefulPartitionedCall_grad/StatefulPartitionedCall_18' with dtype int32\n",
      "\t [[{{node gradients/StatefulPartitionedCall_grad/StatefulPartitionedCall_18}}]]\n",
      "2023-05-23 10:12:49.658205: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/StatefulPartitionedCall_grad/StatefulPartitionedCall_19' with dtype int64 and shape [?,?,?,?]\n",
      "\t [[{{node gradients/StatefulPartitionedCall_grad/StatefulPartitionedCall_19}}]]\n",
      "2023-05-23 10:12:49.976194: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-05-23 10:12:49.977719: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 1\n",
      "2023-05-23 10:12:49.977823: I tensorflow/core/grappler/clusters/single_machine.cc:358] Starting new session\n",
      "2023-05-23 10:12:49.978133: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-05-23 10:12:49.979355: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-05-23 10:12:49.980570: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-05-23 10:12:49.981831: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-05-23 10:12:49.983044: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-05-23 10:12:49.984208: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13221 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:06.0, compute capability: 7.5\n",
      "2023-05-23 10:12:50.069097: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-05-23 10:12:50.070380: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 1\n",
      "2023-05-23 10:12:50.070474: I tensorflow/core/grappler/clusters/single_machine.cc:358] Starting new session\n",
      "2023-05-23 10:12:50.070739: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-05-23 10:12:50.071961: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-05-23 10:12:50.073164: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-05-23 10:12:50.074430: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-05-23 10:12:50.075649: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-05-23 10:12:50.076826: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13221 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:06.0, compute capability: 7.5\n",
      "2023-05-23 10:12:50.085168: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-05-23 10:12:50.086363: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 1\n",
      "2023-05-23 10:12:50.086443: I tensorflow/core/grappler/clusters/single_machine.cc:358] Starting new session\n",
      "2023-05-23 10:12:50.086692: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-05-23 10:12:50.087906: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-05-23 10:12:50.089120: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-05-23 10:12:50.090358: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-05-23 10:12:50.091564: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-05-23 10:12:50.092715: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13221 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:06.0, compute capability: 7.5\n",
      "2023-05-23 10:12:50.103004: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-05-23 10:12:50.104179: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 1\n",
      "2023-05-23 10:12:50.104272: I tensorflow/core/grappler/clusters/single_machine.cc:358] Starting new session\n",
      "2023-05-23 10:12:50.104577: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-05-23 10:12:50.105806: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-05-23 10:12:50.107016: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-05-23 10:12:50.108251: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-05-23 10:12:50.109455: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-05-23 10:12:50.110632: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13221 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:06.0, compute capability: 7.5\n",
      "2023-05-23 10:12:50.123585: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-05-23 10:12:50.124774: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 1\n",
      "2023-05-23 10:12:50.124850: I tensorflow/core/grappler/clusters/single_machine.cc:358] Starting new session\n",
      "2023-05-23 10:12:50.125105: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-05-23 10:12:50.126324: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-05-23 10:12:50.127529: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-05-23 10:12:50.128783: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-05-23 10:12:50.129984: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-05-23 10:12:50.131157: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13221 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:06.0, compute capability: 7.5\n",
      "2023-05-23 10:12:50.148235: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-05-23 10:12:50.149415: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 1\n",
      "2023-05-23 10:12:50.149494: I tensorflow/core/grappler/clusters/single_machine.cc:358] Starting new session\n",
      "2023-05-23 10:12:50.149749: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-05-23 10:12:50.150970: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-05-23 10:12:50.152172: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-05-23 10:12:50.153423: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-05-23 10:12:50.154633: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-05-23 10:12:50.155793: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13221 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:06.0, compute capability: 7.5\n",
      "2023-05-23 10:12:50.157546: E tensorflow/core/grappler/grappler_item_builder.cc:430] Failed to detect the fetch node(s), skipping this input\n",
      "2023-05-23 10:12:50.159020: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-05-23 10:12:50.160186: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 1\n",
      "2023-05-23 10:12:50.160263: I tensorflow/core/grappler/clusters/single_machine.cc:358] Starting new session\n",
      "2023-05-23 10:12:50.160503: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-05-23 10:12:50.161712: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-05-23 10:12:50.162931: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-05-23 10:12:50.164168: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-05-23 10:12:50.165394: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-05-23 10:12:50.166548: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13221 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:06.0, compute capability: 7.5\n",
      "2023-05-23 10:12:50.168154: E tensorflow/core/grappler/grappler_item_builder.cc:430] Failed to detect the fetch node(s), skipping this input\n",
      "2023-05-23 10:12:50.169837: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-05-23 10:12:50.171003: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 1\n",
      "2023-05-23 10:12:50.171070: I tensorflow/core/grappler/clusters/single_machine.cc:358] Starting new session\n",
      "2023-05-23 10:12:50.171320: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-05-23 10:12:50.172529: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-05-23 10:12:50.173741: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-05-23 10:12:50.174970: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-05-23 10:12:50.176179: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-05-23 10:12:50.177345: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13221 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:06.0, compute capability: 7.5\n",
      "2023-05-23 10:12:50.179037: E tensorflow/core/grappler/grappler_item_builder.cc:430] Failed to detect the fetch node(s), skipping this input\n",
      "2023-05-23 10:12:50.180696: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-05-23 10:12:50.181855: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 1\n",
      "2023-05-23 10:12:50.181926: I tensorflow/core/grappler/clusters/single_machine.cc:358] Starting new session\n",
      "2023-05-23 10:12:50.182203: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-05-23 10:12:50.183429: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-05-23 10:12:50.184632: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-05-23 10:12:50.185862: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-05-23 10:12:50.187088: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-05-23 10:12:50.188238: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13221 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:06.0, compute capability: 7.5\n",
      "2023-05-23 10:12:50.190737: E tensorflow/core/grappler/grappler_item_builder.cc:430] Failed to detect the fetch node(s), skipping this input\n",
      "2023-05-23 10:12:50.193483: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-05-23 10:12:50.194665: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 1\n",
      "2023-05-23 10:12:50.194738: I tensorflow/core/grappler/clusters/single_machine.cc:358] Starting new session\n",
      "2023-05-23 10:12:50.194973: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-05-23 10:12:50.196189: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-05-23 10:12:50.197396: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-05-23 10:12:50.198624: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-05-23 10:12:50.199826: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-05-23 10:12:50.200982: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13221 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:06.0, compute capability: 7.5\n",
      "2023-05-23 10:12:50.204701: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-05-23 10:12:50.205867: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 1\n",
      "2023-05-23 10:12:50.205952: I tensorflow/core/grappler/clusters/single_machine.cc:358] Starting new session\n",
      "2023-05-23 10:12:50.206204: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-05-23 10:12:50.207426: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-05-23 10:12:50.208686: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-05-23 10:12:50.209912: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-05-23 10:12:50.211125: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-05-23 10:12:50.212279: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13221 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:06.0, compute capability: 7.5\n",
      "2023-05-23 10:12:50.217845: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-05-23 10:12:50.219011: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 1\n",
      "2023-05-23 10:12:50.219092: I tensorflow/core/grappler/clusters/single_machine.cc:358] Starting new session\n",
      "2023-05-23 10:12:50.219335: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-05-23 10:12:50.220545: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-05-23 10:12:50.221754: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-05-23 10:12:50.222997: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-05-23 10:12:50.224200: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-05-23 10:12:50.225356: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13221 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:06.0, compute capability: 7.5\n",
      "2023-05-23 10:12:50.230820: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-05-23 10:12:50.231992: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 1\n",
      "2023-05-23 10:12:50.232067: I tensorflow/core/grappler/clusters/single_machine.cc:358] Starting new session\n",
      "2023-05-23 10:12:50.232314: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-05-23 10:12:50.233526: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-05-23 10:12:50.234744: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-05-23 10:12:50.236016: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-05-23 10:12:50.237249: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-05-23 10:12:50.238394: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13221 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:06.0, compute capability: 7.5\n",
      "2023-05-23 10:12:50.240049: E tensorflow/core/grappler/grappler_item_builder.cc:430] Failed to detect the fetch node(s), skipping this input\n",
      "2023-05-23 10:12:50.244039: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-05-23 10:12:50.245209: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 1\n",
      "2023-05-23 10:12:50.245285: I tensorflow/core/grappler/clusters/single_machine.cc:358] Starting new session\n",
      "2023-05-23 10:12:50.245525: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-05-23 10:12:50.246753: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-05-23 10:12:50.247960: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-05-23 10:12:50.249190: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-05-23 10:12:50.250410: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-05-23 10:12:50.251560: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13221 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:06.0, compute capability: 7.5\n",
      "2023-05-23 10:12:50.259632: W tensorflow/core/grappler/optimizers/loop_optimizer.cc:907] Skipping loop optimization for Merge node with control input: StatefulPartitionedCall/cond/branch_executed/_16\n",
      "2023-05-23 10:12:50.601531: W external/org_tensorflow/tensorflow/core/framework/op_kernel.cc:1807] OP_REQUIRES failed at map_dataset_op.cc:244 : NOT_FOUND: Op type not registered 'RegexSplitWithOffsets' in binary running on kilian-tf. Make sure the Op and Kernel are registered in the binary running in this process. Note that if you are loading a saved graph which used ops from tf.contrib, accessing (e.g.) `tf.contrib.resampler` should be done before importing the graph, as contrib ops are lazily registered when the module is first accessed.\n",
      "2023-05-23 10:12:50.601835: W external/org_tensorflow/tensorflow/core/framework/op_kernel.cc:1830] OP_REQUIRES failed at dataset_ops.cc:151 : NOT_FOUND: Op type not registered 'RegexSplitWithOffsets' in binary running on kilian-tf. Make sure the Op and Kernel are registered in the binary running in this process. Note that if you are loading a saved graph which used ops from tf.contrib, accessing (e.g.) `tf.contrib.resampler` should be done before importing the graph, as contrib ops are lazily registered when the module is first accessed.\n",
      "\t [[{{node MapDataset/_9}}]]\n",
      "2023-05-23 10:12:50.604861: E tensorflow_federated/cc/core/impl/executors/tensorflow_executor.cc:711] Failed to run computation: Op type not registered 'RegexSplitWithOffsets' in binary running on kilian-tf. Make sure the Op and Kernel are registered in the binary running in this process. Note that if you are loading a saved graph which used ops from tf.contrib, accessing (e.g.) `tf.contrib.resampler` should be done before importing the graph, as contrib ops are lazily registered when the module is first accessed.\n",
      "\t [[{{node MapDataset/_9}}]]\n",
      "\t [[root/1/Placeholder/DatasetFromGraph]]\n",
      "2023-05-23 10:12:50.690018: W external/org_tensorflow/tensorflow/core/framework/op_kernel.cc:1807] OP_REQUIRES failed at map_dataset_op.cc:244 : NOT_FOUND: Op type not registered 'RegexSplitWithOffsets' in binary running on kilian-tf. Make sure the Op and Kernel are registered in the binary running in this process. Note that if you are loading a saved graph which used ops from tf.contrib, accessing (e.g.) `tf.contrib.resampler` should be done before importing the graph, as contrib ops are lazily registered when the module is first accessed.\n",
      "2023-05-23 10:12:50.690256: W external/org_tensorflow/tensorflow/core/framework/op_kernel.cc:1830] OP_REQUIRES failed at dataset_ops.cc:151 : NOT_FOUND: Op type not registered 'RegexSplitWithOffsets' in binary running on kilian-tf. Make sure the Op and Kernel are registered in the binary running in this process. Note that if you are loading a saved graph which used ops from tf.contrib, accessing (e.g.) `tf.contrib.resampler` should be done before importing the graph, as contrib ops are lazily registered when the module is first accessed.\n",
      "\t [[{{node MapDataset/_9}}]]\n",
      "2023-05-23 10:12:50.692716: E tensorflow_federated/cc/core/impl/executors/tensorflow_executor.cc:711] Failed to run computation: Op type not registered 'RegexSplitWithOffsets' in binary running on kilian-tf. Make sure the Op and Kernel are registered in the binary running in this process. Note that if you are loading a saved graph which used ops from tf.contrib, accessing (e.g.) `tf.contrib.resampler` should be done before importing the graph, as contrib ops are lazily registered when the module is first accessed.\n",
      "\t [[{{node MapDataset/_9}}]]\n",
      "\t [[root/1/Placeholder/DatasetFromGraph]]\n",
      "2023-05-23 10:12:50.697572: W external/org_tensorflow/tensorflow/core/framework/op_kernel.cc:1807] OP_REQUIRES failed at map_dataset_op.cc:244 : NOT_FOUND: Op type not registered 'RegexSplitWithOffsets' in binary running on kilian-tf. Make sure the Op and Kernel are registered in the binary running in this process. Note that if you are loading a saved graph which used ops from tf.contrib, accessing (e.g.) `tf.contrib.resampler` should be done before importing the graph, as contrib ops are lazily registered when the module is first accessed.\n",
      "2023-05-23 10:12:50.697669: W external/org_tensorflow/tensorflow/core/framework/op_kernel.cc:1830] OP_REQUIRES failed at dataset_ops.cc:151 : NOT_FOUND: Op type not registered 'RegexSplitWithOffsets' in binary running on kilian-tf. Make sure the Op and Kernel are registered in the binary running in this process. Note that if you are loading a saved graph which used ops from tf.contrib, accessing (e.g.) `tf.contrib.resampler` should be done before importing the graph, as contrib ops are lazily registered when the module is first accessed.\n",
      "\t [[{{node MapDataset/_9}}]]\n",
      "2023-05-23 10:12:50.699880: E tensorflow_federated/cc/core/impl/executors/tensorflow_executor.cc:711] Failed to run computation: Op type not registered 'RegexSplitWithOffsets' in binary running on kilian-tf. Make sure the Op and Kernel are registered in the binary running in this process. Note that if you are loading a saved graph which used ops from tf.contrib, accessing (e.g.) `tf.contrib.resampler` should be done before importing the graph, as contrib ops are lazily registered when the module is first accessed.\n",
      "\t [[{{node MapDataset/_9}}]]\n",
      "\t [[root/1/Placeholder/DatasetFromGraph]]\n",
      "2023-05-23 10:12:50.704217: W external/org_tensorflow/tensorflow/core/framework/op_kernel.cc:1807] OP_REQUIRES failed at map_dataset_op.cc:244 : NOT_FOUND: Op type not registered 'RegexSplitWithOffsets' in binary running on kilian-tf. Make sure the Op and Kernel are registered in the binary running in this process. Note that if you are loading a saved graph which used ops from tf.contrib, accessing (e.g.) `tf.contrib.resampler` should be done before importing the graph, as contrib ops are lazily registered when the module is first accessed.\n",
      "2023-05-23 10:12:50.704324: W external/org_tensorflow/tensorflow/core/framework/op_kernel.cc:1830] OP_REQUIRES failed at dataset_ops.cc:151 : NOT_FOUND: Op type not registered 'RegexSplitWithOffsets' in binary running on kilian-tf. Make sure the Op and Kernel are registered in the binary running in this process. Note that if you are loading a saved graph which used ops from tf.contrib, accessing (e.g.) `tf.contrib.resampler` should be done before importing the graph, as contrib ops are lazily registered when the module is first accessed.\n",
      "\t [[{{node MapDataset/_9}}]]\n",
      "2023-05-23 10:12:50.706896: E tensorflow_federated/cc/core/impl/executors/tensorflow_executor.cc:711] Failed to run computation: Op type not registered 'RegexSplitWithOffsets' in binary running on kilian-tf. Make sure the Op and Kernel are registered in the binary running in this process. Note that if you are loading a saved graph which used ops from tf.contrib, accessing (e.g.) `tf.contrib.resampler` should be done before importing the graph, as contrib ops are lazily registered when the module is first accessed.\n",
      "\t [[{{node MapDataset/_9}}]]\n",
      "\t [[root/1/Placeholder/DatasetFromGraph]]\n",
      "2023-05-23 10:12:50.769810: W external/org_tensorflow/tensorflow/core/framework/op_kernel.cc:1807] OP_REQUIRES failed at map_dataset_op.cc:244 : NOT_FOUND: Op type not registered 'RegexSplitWithOffsets' in binary running on kilian-tf. Make sure the Op and Kernel are registered in the binary running in this process. Note that if you are loading a saved graph which used ops from tf.contrib, accessing (e.g.) `tf.contrib.resampler` should be done before importing the graph, as contrib ops are lazily registered when the module is first accessed.\n",
      "2023-05-23 10:12:50.769926: W external/org_tensorflow/tensorflow/core/framework/op_kernel.cc:1830] OP_REQUIRES failed at dataset_ops.cc:151 : NOT_FOUND: Op type not registered 'RegexSplitWithOffsets' in binary running on kilian-tf. Make sure the Op and Kernel are registered in the binary running in this process. Note that if you are loading a saved graph which used ops from tf.contrib, accessing (e.g.) `tf.contrib.resampler` should be done before importing the graph, as contrib ops are lazily registered when the module is first accessed.\n",
      "\t [[{{node MapDataset/_9}}]]\n",
      "2023-05-23 10:12:50.772055: E tensorflow_federated/cc/core/impl/executors/tensorflow_executor.cc:711] Failed to run computation: Op type not registered 'RegexSplitWithOffsets' in binary running on kilian-tf. Make sure the Op and Kernel are registered in the binary running in this process. Note that if you are loading a saved graph which used ops from tf.contrib, accessing (e.g.) `tf.contrib.resampler` should be done before importing the graph, as contrib ops are lazily registered when the module is first accessed.\n",
      "\t [[{{node MapDataset/_9}}]]\n",
      "\t [[root/1/Placeholder/DatasetFromGraph]]\n",
      "2023-05-23 10:12:50.776441: W external/org_tensorflow/tensorflow/core/framework/op_kernel.cc:1807] OP_REQUIRES failed at map_dataset_op.cc:244 : NOT_FOUND: Op type not registered 'RegexSplitWithOffsets' in binary running on kilian-tf. Make sure the Op and Kernel are registered in the binary running in this process. Note that if you are loading a saved graph which used ops from tf.contrib, accessing (e.g.) `tf.contrib.resampler` should be done before importing the graph, as contrib ops are lazily registered when the module is first accessed.\n",
      "2023-05-23 10:12:50.776572: W external/org_tensorflow/tensorflow/core/framework/op_kernel.cc:1830] OP_REQUIRES failed at dataset_ops.cc:151 : NOT_FOUND: Op type not registered 'RegexSplitWithOffsets' in binary running on kilian-tf. Make sure the Op and Kernel are registered in the binary running in this process. Note that if you are loading a saved graph which used ops from tf.contrib, accessing (e.g.) `tf.contrib.resampler` should be done before importing the graph, as contrib ops are lazily registered when the module is first accessed.\n",
      "\t [[{{node MapDataset/_9}}]]\n",
      "2023-05-23 10:12:50.779748: E tensorflow_federated/cc/core/impl/executors/tensorflow_executor.cc:711] Failed to run computation: Op type not registered 'RegexSplitWithOffsets' in binary running on kilian-tf. Make sure the Op and Kernel are registered in the binary running in this process. Note that if you are loading a saved graph which used ops from tf.contrib, accessing (e.g.) `tf.contrib.resampler` should be done before importing the graph, as contrib ops are lazily registered when the module is first accessed.\n",
      "\t [[{{node MapDataset/_9}}]]\n",
      "\t [[root/1/Placeholder/DatasetFromGraph]]\n",
      "2023-05-23 10:12:50.780072: W external/org_tensorflow/tensorflow/core/framework/op_kernel.cc:1807] OP_REQUIRES failed at map_dataset_op.cc:244 : NOT_FOUND: Op type not registered 'RegexSplitWithOffsets' in binary running on kilian-tf. Make sure the Op and Kernel are registered in the binary running in this process. Note that if you are loading a saved graph which used ops from tf.contrib, accessing (e.g.) `tf.contrib.resampler` should be done before importing the graph, as contrib ops are lazily registered when the module is first accessed.\n",
      "2023-05-23 10:12:50.780185: W external/org_tensorflow/tensorflow/core/framework/op_kernel.cc:1830] OP_REQUIRES failed at dataset_ops.cc:151 : NOT_FOUND: Op type not registered 'RegexSplitWithOffsets' in binary running on kilian-tf. Make sure the Op and Kernel are registered in the binary running in this process. Note that if you are loading a saved graph which used ops from tf.contrib, accessing (e.g.) `tf.contrib.resampler` should be done before importing the graph, as contrib ops are lazily registered when the module is first accessed.\n",
      "\t [[{{node MapDataset/_9}}]]\n",
      "2023-05-23 10:12:50.781753: W external/org_tensorflow/tensorflow/core/framework/op_kernel.cc:1807] OP_REQUIRES failed at map_dataset_op.cc:244 : NOT_FOUND: Op type not registered 'RegexSplitWithOffsets' in binary running on kilian-tf. Make sure the Op and Kernel are registered in the binary running in this process. Note that if you are loading a saved graph which used ops from tf.contrib, accessing (e.g.) `tf.contrib.resampler` should be done before importing the graph, as contrib ops are lazily registered when the module is first accessed.\n",
      "2023-05-23 10:12:50.781861: W external/org_tensorflow/tensorflow/core/framework/op_kernel.cc:1830] OP_REQUIRES failed at dataset_ops.cc:151 : NOT_FOUND: Op type not registered 'RegexSplitWithOffsets' in binary running on kilian-tf. Make sure the Op and Kernel are registered in the binary running in this process. Note that if you are loading a saved graph which used ops from tf.contrib, accessing (e.g.) `tf.contrib.resampler` should be done before importing the graph, as contrib ops are lazily registered when the module is first accessed.\n",
      "\t [[{{node MapDataset/_9}}]]\n",
      "2023-05-23 10:12:50.783781: E tensorflow_federated/cc/core/impl/executors/tensorflow_executor.cc:711] Failed to run computation: Op type not registered 'RegexSplitWithOffsets' in binary running on kilian-tf. Make sure the Op and Kernel are registered in the binary running in this process. Note that if you are loading a saved graph which used ops from tf.contrib, accessing (e.g.) `tf.contrib.resampler` should be done before importing the graph, as contrib ops are lazily registered when the module is first accessed.\n",
      "\t [[{{node MapDataset/_9}}]]\n",
      "\t [[root/1/Placeholder/DatasetFromGraph]]\n",
      "2023-05-23 10:12:50.784079: E tensorflow_federated/cc/core/impl/executors/tensorflow_executor.cc:711] Failed to run computation: Op type not registered 'RegexSplitWithOffsets' in binary running on kilian-tf. Make sure the Op and Kernel are registered in the binary running in this process. Note that if you are loading a saved graph which used ops from tf.contrib, accessing (e.g.) `tf.contrib.resampler` should be done before importing the graph, as contrib ops are lazily registered when the module is first accessed.\n",
      "\t [[{{node MapDataset/_9}}]]\n",
      "\t [[root/1/Placeholder/DatasetFromGraph]]\n",
      "2023-05-23 10:12:50.789436: W external/org_tensorflow/tensorflow/core/framework/op_kernel.cc:1807] OP_REQUIRES failed at map_dataset_op.cc:244 : NOT_FOUND: Op type not registered 'RegexSplitWithOffsets' in binary running on kilian-tf. Make sure the Op and Kernel are registered in the binary running in this process. Note that if you are loading a saved graph which used ops from tf.contrib, accessing (e.g.) `tf.contrib.resampler` should be done before importing the graph, as contrib ops are lazily registered when the module is first accessed.\n",
      "2023-05-23 10:12:50.789530: W external/org_tensorflow/tensorflow/core/framework/op_kernel.cc:1830] OP_REQUIRES failed at dataset_ops.cc:151 : NOT_FOUND: Op type not registered 'RegexSplitWithOffsets' in binary running on kilian-tf. Make sure the Op and Kernel are registered in the binary running in this process. Note that if you are loading a saved graph which used ops from tf.contrib, accessing (e.g.) `tf.contrib.resampler` should be done before importing the graph, as contrib ops are lazily registered when the module is first accessed.\n",
      "\t [[{{node MapDataset/_9}}]]\n",
      "2023-05-23 10:12:50.791700: E tensorflow_federated/cc/core/impl/executors/tensorflow_executor.cc:711] Failed to run computation: Op type not registered 'RegexSplitWithOffsets' in binary running on kilian-tf. Make sure the Op and Kernel are registered in the binary running in this process. Note that if you are loading a saved graph which used ops from tf.contrib, accessing (e.g.) `tf.contrib.resampler` should be done before importing the graph, as contrib ops are lazily registered when the module is first accessed.\n",
      "\t [[{{node MapDataset/_9}}]]\n",
      "\t [[root/1/Placeholder/DatasetFromGraph]]\n",
      "2023-05-23 10:12:50.794306: W external/org_tensorflow/tensorflow/core/framework/op_kernel.cc:1807] OP_REQUIRES failed at map_dataset_op.cc:244 : NOT_FOUND: Op type not registered 'RegexSplitWithOffsets' in binary running on kilian-tf. Make sure the Op and Kernel are registered in the binary running in this process. Note that if you are loading a saved graph which used ops from tf.contrib, accessing (e.g.) `tf.contrib.resampler` should be done before importing the graph, as contrib ops are lazily registered when the module is first accessed.\n",
      "2023-05-23 10:12:50.794392: W external/org_tensorflow/tensorflow/core/framework/op_kernel.cc:1830] OP_REQUIRES failed at dataset_ops.cc:151 : NOT_FOUND: Op type not registered 'RegexSplitWithOffsets' in binary running on kilian-tf. Make sure the Op and Kernel are registered in the binary running in this process. Note that if you are loading a saved graph which used ops from tf.contrib, accessing (e.g.) `tf.contrib.resampler` should be done before importing the graph, as contrib ops are lazily registered when the module is first accessed.\n",
      "\t [[{{node MapDataset/_9}}]]\n",
      "2023-05-23 10:12:50.795463: W external/org_tensorflow/tensorflow/core/framework/op_kernel.cc:1807] OP_REQUIRES failed at map_dataset_op.cc:244 : NOT_FOUND: Op type not registered 'RegexSplitWithOffsets' in binary running on kilian-tf. Make sure the Op and Kernel are registered in the binary running in this process. Note that if you are loading a saved graph which used ops from tf.contrib, accessing (e.g.) `tf.contrib.resampler` should be done before importing the graph, as contrib ops are lazily registered when the module is first accessed.\n",
      "2023-05-23 10:12:50.795545: W external/org_tensorflow/tensorflow/core/framework/op_kernel.cc:1830] OP_REQUIRES failed at dataset_ops.cc:151 : NOT_FOUND: Op type not registered 'RegexSplitWithOffsets' in binary running on kilian-tf. Make sure the Op and Kernel are registered in the binary running in this process. Note that if you are loading a saved graph which used ops from tf.contrib, accessing (e.g.) `tf.contrib.resampler` should be done before importing the graph, as contrib ops are lazily registered when the module is first accessed.\n",
      "\t [[{{node MapDataset/_9}}]]\n",
      "2023-05-23 10:12:50.797226: W external/org_tensorflow/tensorflow/core/framework/op_kernel.cc:1807] OP_REQUIRES failed at map_dataset_op.cc:244 : NOT_FOUND: Op type not registered 'RegexSplitWithOffsets' in binary running on kilian-tf. Make sure the Op and Kernel are registered in the binary running in this process. Note that if you are loading a saved graph which used ops from tf.contrib, accessing (e.g.) `tf.contrib.resampler` should be done before importing the graph, as contrib ops are lazily registered when the module is first accessed.\n",
      "2023-05-23 10:12:50.797337: W external/org_tensorflow/tensorflow/core/framework/op_kernel.cc:1830] OP_REQUIRES failed at dataset_ops.cc:151 : NOT_FOUND: Op type not registered 'RegexSplitWithOffsets' in binary running on kilian-tf. Make sure the Op and Kernel are registered in the binary running in this process. Note that if you are loading a saved graph which used ops from tf.contrib, accessing (e.g.) `tf.contrib.resampler` should be done before importing the graph, as contrib ops are lazily registered when the module is first accessed.\n",
      "\t [[{{node MapDataset/_9}}]]\n",
      "2023-05-23 10:12:50.797356: E tensorflow_federated/cc/core/impl/executors/tensorflow_executor.cc:711] Failed to run computation: Op type not registered 'RegexSplitWithOffsets' in binary running on kilian-tf. Make sure the Op and Kernel are registered in the binary running in this process. Note that if you are loading a saved graph which used ops from tf.contrib, accessing (e.g.) `tf.contrib.resampler` should be done before importing the graph, as contrib ops are lazily registered when the module is first accessed.\n",
      "\t [[{{node MapDataset/_9}}]]\n",
      "\t [[root/1/Placeholder/DatasetFromGraph]]\n",
      "2023-05-23 10:12:50.797735: E tensorflow_federated/cc/core/impl/executors/tensorflow_executor.cc:711] Failed to run computation: Op type not registered 'RegexSplitWithOffsets' in binary running on kilian-tf. Make sure the Op and Kernel are registered in the binary running in this process. Note that if you are loading a saved graph which used ops from tf.contrib, accessing (e.g.) `tf.contrib.resampler` should be done before importing the graph, as contrib ops are lazily registered when the module is first accessed.\n",
      "\t [[{{node MapDataset/_9}}]]\n",
      "\t [[root/1/Placeholder/DatasetFromGraph]]\n",
      "2023-05-23 10:12:50.798572: W external/org_tensorflow/tensorflow/core/framework/op_kernel.cc:1807] OP_REQUIRES failed at map_dataset_op.cc:244 : NOT_FOUND: Op type not registered 'RegexSplitWithOffsets' in binary running on kilian-tf. Make sure the Op and Kernel are registered in the binary running in this process. Note that if you are loading a saved graph which used ops from tf.contrib, accessing (e.g.) `tf.contrib.resampler` should be done before importing the graph, as contrib ops are lazily registered when the module is first accessed.\n",
      "2023-05-23 10:12:50.798688: W external/org_tensorflow/tensorflow/core/framework/op_kernel.cc:1830] OP_REQUIRES failed at dataset_ops.cc:151 : NOT_FOUND: Op type not registered 'RegexSplitWithOffsets' in binary running on kilian-tf. Make sure the Op and Kernel are registered in the binary running in this process. Note that if you are loading a saved graph which used ops from tf.contrib, accessing (e.g.) `tf.contrib.resampler` should be done before importing the graph, as contrib ops are lazily registered when the module is first accessed.\n",
      "\t [[{{node MapDataset/_9}}]]\n",
      "2023-05-23 10:12:50.800427: E tensorflow_federated/cc/core/impl/executors/tensorflow_executor.cc:711] Failed to run computation: Op type not registered 'RegexSplitWithOffsets' in binary running on kilian-tf. Make sure the Op and Kernel are registered in the binary running in this process. Note that if you are loading a saved graph which used ops from tf.contrib, accessing (e.g.) `tf.contrib.resampler` should be done before importing the graph, as contrib ops are lazily registered when the module is first accessed.\n",
      "\t [[{{node MapDataset/_9}}]]\n",
      "\t [[root/1/Placeholder/DatasetFromGraph]]\n",
      "2023-05-23 10:12:50.801588: W external/org_tensorflow/tensorflow/core/framework/op_kernel.cc:1807] OP_REQUIRES failed at map_dataset_op.cc:244 : NOT_FOUND: Op type not registered 'RegexSplitWithOffsets' in binary running on kilian-tf. Make sure the Op and Kernel are registered in the binary running in this process. Note that if you are loading a saved graph which used ops from tf.contrib, accessing (e.g.) `tf.contrib.resampler` should be done before importing the graph, as contrib ops are lazily registered when the module is first accessed.\n",
      "2023-05-23 10:12:50.802534: E tensorflow_federated/cc/core/impl/executors/tensorflow_executor.cc:711] Failed to run computation: Op type not registered 'RegexSplitWithOffsets' in binary running on kilian-tf. Make sure the Op and Kernel are registered in the binary running in this process. Note that if you are loading a saved graph which used ops from tf.contrib, accessing (e.g.) `tf.contrib.resampler` should be done before importing the graph, as contrib ops are lazily registered when the module is first accessed.\n",
      "\t [[{{node MapDataset/_9}}]]\n",
      "\t [[root/1/Placeholder/DatasetFromGraph]]\n",
      "2023-05-23 10:12:50.802577: W external/org_tensorflow/tensorflow/core/framework/op_kernel.cc:1807] OP_REQUIRES failed at map_dataset_op.cc:244 : NOT_FOUND: Op type not registered 'RegexSplitWithOffsets' in binary running on kilian-tf. Make sure the Op and Kernel are registered in the binary running in this process. Note that if you are loading a saved graph which used ops from tf.contrib, accessing (e.g.) `tf.contrib.resampler` should be done before importing the graph, as contrib ops are lazily registered when the module is first accessed.\n",
      "2023-05-23 10:12:50.802602: W external/org_tensorflow/tensorflow/core/framework/op_kernel.cc:1830] OP_REQUIRES failed at dataset_ops.cc:151 : NOT_FOUND: Op type not registered 'RegexSplitWithOffsets' in binary running on kilian-tf. Make sure the Op and Kernel are registered in the binary running in this process. Note that if you are loading a saved graph which used ops from tf.contrib, accessing (e.g.) `tf.contrib.resampler` should be done before importing the graph, as contrib ops are lazily registered when the module is first accessed.\n",
      "\t [[{{node MapDataset/_9}}]]\n",
      "2023-05-23 10:12:50.802657: W external/org_tensorflow/tensorflow/core/framework/op_kernel.cc:1830] OP_REQUIRES failed at dataset_ops.cc:151 : NOT_FOUND: Op type not registered 'RegexSplitWithOffsets' in binary running on kilian-tf. Make sure the Op and Kernel are registered in the binary running in this process. Note that if you are loading a saved graph which used ops from tf.contrib, accessing (e.g.) `tf.contrib.resampler` should be done before importing the graph, as contrib ops are lazily registered when the module is first accessed.\n",
      "\t [[{{node MapDataset/_9}}]]\n",
      "2023-05-23 10:12:50.805598: E tensorflow_federated/cc/core/impl/executors/tensorflow_executor.cc:711] Failed to run computation: Op type not registered 'RegexSplitWithOffsets' in binary running on kilian-tf. Make sure the Op and Kernel are registered in the binary running in this process. Note that if you are loading a saved graph which used ops from tf.contrib, accessing (e.g.) `tf.contrib.resampler` should be done before importing the graph, as contrib ops are lazily registered when the module is first accessed.\n",
      "\t [[{{node MapDataset/_9}}]]\n",
      "\t [[root/1/Placeholder/DatasetFromGraph]]\n",
      "2023-05-23 10:12:50.808626: W external/org_tensorflow/tensorflow/core/framework/op_kernel.cc:1807] OP_REQUIRES failed at map_dataset_op.cc:244 : NOT_FOUND: Op type not registered 'RegexSplitWithOffsets' in binary running on kilian-tf. Make sure the Op and Kernel are registered in the binary running in this process. Note that if you are loading a saved graph which used ops from tf.contrib, accessing (e.g.) `tf.contrib.resampler` should be done before importing the graph, as contrib ops are lazily registered when the module is first accessed.\n",
      "2023-05-23 10:12:50.808707: W external/org_tensorflow/tensorflow/core/framework/op_kernel.cc:1830] OP_REQUIRES failed at dataset_ops.cc:151 : NOT_FOUND: Op type not registered 'RegexSplitWithOffsets' in binary running on kilian-tf. Make sure the Op and Kernel are registered in the binary running in this process. Note that if you are loading a saved graph which used ops from tf.contrib, accessing (e.g.) `tf.contrib.resampler` should be done before importing the graph, as contrib ops are lazily registered when the module is first accessed.\n",
      "\t [[{{node MapDataset/_9}}]]\n",
      "2023-05-23 10:12:50.808953: E tensorflow_federated/cc/core/impl/executors/tensorflow_executor.cc:711] Failed to run computation: Op type not registered 'RegexSplitWithOffsets' in binary running on kilian-tf. Make sure the Op and Kernel are registered in the binary running in this process. Note that if you are loading a saved graph which used ops from tf.contrib, accessing (e.g.) `tf.contrib.resampler` should be done before importing the graph, as contrib ops are lazily registered when the module is first accessed.\n",
      "\t [[{{node MapDataset/_9}}]]\n",
      "\t [[root/1/Placeholder/DatasetFromGraph]]\n",
      "2023-05-23 10:12:50.810711: W external/org_tensorflow/tensorflow/core/framework/op_kernel.cc:1807] OP_REQUIRES failed at map_dataset_op.cc:244 : NOT_FOUND: Op type not registered 'RegexSplitWithOffsets' in binary running on kilian-tf. Make sure the Op and Kernel are registered in the binary running in this process. Note that if you are loading a saved graph which used ops from tf.contrib, accessing (e.g.) `tf.contrib.resampler` should be done before importing the graph, as contrib ops are lazily registered when the module is first accessed.\n",
      "2023-05-23 10:12:50.810789: W external/org_tensorflow/tensorflow/core/framework/op_kernel.cc:1807] OP_REQUIRES failed at map_dataset_op.cc:244 : NOT_FOUND: Op type not registered 'RegexSplitWithOffsets' in binary running on kilian-tf. Make sure the Op and Kernel are registered in the binary running in this process. Note that if you are loading a saved graph which used ops from tf.contrib, accessing (e.g.) `tf.contrib.resampler` should be done before importing the graph, as contrib ops are lazily registered when the module is first accessed.\n",
      "2023-05-23 10:12:50.810815: W external/org_tensorflow/tensorflow/core/framework/op_kernel.cc:1830] OP_REQUIRES failed at dataset_ops.cc:151 : NOT_FOUND: Op type not registered 'RegexSplitWithOffsets' in binary running on kilian-tf. Make sure the Op and Kernel are registered in the binary running in this process. Note that if you are loading a saved graph which used ops from tf.contrib, accessing (e.g.) `tf.contrib.resampler` should be done before importing the graph, as contrib ops are lazily registered when the module is first accessed.\n",
      "\t [[{{node MapDataset/_9}}]]\n",
      "2023-05-23 10:12:50.810886: W external/org_tensorflow/tensorflow/core/framework/op_kernel.cc:1830] OP_REQUIRES failed at dataset_ops.cc:151 : NOT_FOUND: Op type not registered 'RegexSplitWithOffsets' in binary running on kilian-tf. Make sure the Op and Kernel are registered in the binary running in this process. Note that if you are loading a saved graph which used ops from tf.contrib, accessing (e.g.) `tf.contrib.resampler` should be done before importing the graph, as contrib ops are lazily registered when the module is first accessed.\n",
      "\t [[{{node MapDataset/_9}}]]\n",
      "2023-05-23 10:12:50.811615: E tensorflow_federated/cc/core/impl/executors/tensorflow_executor.cc:711] Failed to run computation: Op type not registered 'RegexSplitWithOffsets' in binary running on kilian-tf. Make sure the Op and Kernel are registered in the binary running in this process. Note that if you are loading a saved graph which used ops from tf.contrib, accessing (e.g.) `tf.contrib.resampler` should be done before importing the graph, as contrib ops are lazily registered when the module is first accessed.\n",
      "\t [[{{node MapDataset/_9}}]]\n",
      "\t [[root/1/Placeholder/DatasetFromGraph]]\n",
      "2023-05-23 10:12:50.813164: E tensorflow_federated/cc/core/impl/executors/tensorflow_executor.cc:711] Failed to run computation: Op type not registered 'RegexSplitWithOffsets' in binary running on kilian-tf. Make sure the Op and Kernel are registered in the binary running in this process. Note that if you are loading a saved graph which used ops from tf.contrib, accessing (e.g.) `tf.contrib.resampler` should be done before importing the graph, as contrib ops are lazily registered when the module is first accessed.\n",
      "\t [[{{node MapDataset/_9}}]]\n",
      "\t [[root/1/Placeholder/DatasetFromGraph]]\n",
      "2023-05-23 10:12:50.813236: E tensorflow_federated/cc/core/impl/executors/tensorflow_executor.cc:711] Failed to run computation: Op type not registered 'RegexSplitWithOffsets' in binary running on kilian-tf. Make sure the Op and Kernel are registered in the binary running in this process. Note that if you are loading a saved graph which used ops from tf.contrib, accessing (e.g.) `tf.contrib.resampler` should be done before importing the graph, as contrib ops are lazily registered when the module is first accessed.\n",
      "\t [[{{node MapDataset/_9}}]]\n",
      "\t [[root/1/Placeholder/DatasetFromGraph]]\n"
     ]
    },
    {
     "ename": "_InactiveRpcError",
     "evalue": "<_InactiveRpcError of RPC that terminated with:\n\tstatus = StatusCode.INTERNAL\n\tdetails = \"Failed to run computation: Op type not registered 'RegexSplitWithOffsets' in binary running on kilian-tf. Make sure the Op and Kernel are registered in the binary running in this process. Note that if you are loading a saved graph which used ops from tf.contrib, accessing (e.g.) `tf.contrib.resampler` should be done before importing the graph, as contrib ops are lazily registered when the module is first accessed.\n\t [[{{node MapDataset/_9}}]]\n\t [[root/1/Placeholder/DatasetFromGraph]] while evaluating local [_ovm25] in block locals [_ovm3,_ovm4,_ovm5,_ovm6,_ovm20,_ovm21,_ovm22,_ovm23,_ovm24,_ovm25,_ovm26,_ovm27,_ovm28,_ovm53,_ovm54,_ovm55,_ovm56,_ovm57,_ovm58,_ovm59,_ovm60,_ovm61,_ovm62,_ovm63,_ovm64,_ovm65,_ovm66,_ovm67,_ovm68,_ovm69,_ovm78,_ovm79,_ovm80,_ovm81,_ovm82,_ovm83,_ovm84,_ovm85,_ovm86,_ovm87,_ovm88,_ovm89]\"\n\tdebug_error_string = \"UNKNOWN:Error received from peer ipv6:%5B::1%5D:38263 {created_time:\"2023-05-23T10:12:50.801675196+00:00\", grpc_status:13, grpc_message:\"Failed to run computation: Op type not registered \\'RegexSplitWithOffsets\\' in binary running on kilian-tf. Make sure the Op and Kernel are registered in the binary running in this process. Note that if you are loading a saved graph which used ops from tf.contrib, accessing (e.g.) `tf.contrib.resampler` should be done before importing the graph, as contrib ops are lazily registered when the module is first accessed.\\n\\t [[{{node MapDataset/_9}}]]\\n\\t [[root/1/Placeholder/DatasetFromGraph]] while evaluating local [_ovm25] in block locals [_ovm3,_ovm4,_ovm5,_ovm6,_ovm20,_ovm21,_ovm22,_ovm23,_ovm24,_ovm25,_ovm26,_ovm27,_ovm28,_ovm53,_ovm54,_ovm55,_ovm56,_ovm57,_ovm58,_ovm59,_ovm60,_ovm61,_ovm62,_ovm63,_ovm64,_ovm65,_ovm66,_ovm67,_ovm68,_ovm69,_ovm78,_ovm79,_ovm80,_ovm81,_ovm82,_ovm83,_ovm84,_ovm85,_ovm86,_ovm87,_ovm88,_ovm89]\"}\"\n>",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31m_InactiveRpcError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 28\u001b[0m\n\u001b[1;32m     26\u001b[0m iterative_process \u001b[39m=\u001b[39m get_iterative_process(Noise, n_clients)\n\u001b[1;32m     27\u001b[0m state \u001b[39m=\u001b[39m iterative_process\u001b[39m.\u001b[39minitialize()\n\u001b[0;32m---> 28\u001b[0m state, metrics \u001b[39m=\u001b[39m iterative_process\u001b[39m.\u001b[39;49mnext(state, train_data)\n\u001b[1;32m     30\u001b[0m \u001b[39m# for round_num in range(4):\u001b[39;00m\n\u001b[1;32m     31\u001b[0m \u001b[39m#     state, metrics = iterative_process.next(state, train_data)\u001b[39;00m\n\u001b[1;32m     32\u001b[0m \u001b[39m#     print(f\"Round {round_num+1} - Train Loss: {metrics['loss']}\")\u001b[39;00m\n",
      "File \u001b[0;32m~/federated/venv/lib/python3.9/site-packages/tensorflow_federated/python/core/impl/computation/computation_impl.py:139\u001b[0m, in \u001b[0;36mConcreteComputation.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    137\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    138\u001b[0m   arg \u001b[39m=\u001b[39m function_utils\u001b[39m.\u001b[39mpack_args(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_type_signature\u001b[39m.\u001b[39mparameter, args, kwargs)\n\u001b[0;32m--> 139\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_context_stack\u001b[39m.\u001b[39;49mcurrent\u001b[39m.\u001b[39;49minvoke(\u001b[39mself\u001b[39;49m, arg)\n",
      "File \u001b[0;32m~/federated/venv/lib/python3.9/site-packages/tensorflow_federated/python/core/impl/execution_contexts/sync_execution_context.py:65\u001b[0m, in \u001b[0;36mSyncExecutionContext.invoke\u001b[0;34m(self, comp, arg)\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39minvoke\u001b[39m(\u001b[39mself\u001b[39m, comp, arg):\n\u001b[0;32m---> 65\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_async_runner\u001b[39m.\u001b[39;49mrun_coro_and_return_result(\n\u001b[1;32m     66\u001b[0m       \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_async_context\u001b[39m.\u001b[39;49minvoke(comp, arg)\n\u001b[1;32m     67\u001b[0m   )\n",
      "File \u001b[0;32m~/federated/venv/lib/python3.9/site-packages/tensorflow_federated/python/common_libs/async_utils.py:224\u001b[0m, in \u001b[0;36mAsyncThreadRunner.run_coro_and_return_result\u001b[0;34m(self, coro)\u001b[0m\n\u001b[1;32m    222\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Runs coroutine in the managed event loop, returning the result.\"\"\"\u001b[39;00m\n\u001b[1;32m    223\u001b[0m future \u001b[39m=\u001b[39m asyncio\u001b[39m.\u001b[39mrun_coroutine_threadsafe(coro, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_event_loop)\n\u001b[0;32m--> 224\u001b[0m \u001b[39mreturn\u001b[39;00m future\u001b[39m.\u001b[39;49mresult()\n",
      "File \u001b[0;32m/usr/lib/python3.9/concurrent/futures/_base.py:445\u001b[0m, in \u001b[0;36mFuture.result\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    443\u001b[0m     \u001b[39mraise\u001b[39;00m CancelledError()\n\u001b[1;32m    444\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_state \u001b[39m==\u001b[39m FINISHED:\n\u001b[0;32m--> 445\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m__get_result()\n\u001b[1;32m    446\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    447\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTimeoutError\u001b[39;00m()\n",
      "File \u001b[0;32m/usr/lib/python3.9/concurrent/futures/_base.py:390\u001b[0m, in \u001b[0;36mFuture.__get_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    388\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_exception:\n\u001b[1;32m    389\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 390\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_exception\n\u001b[1;32m    391\u001b[0m     \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m    392\u001b[0m         \u001b[39m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[1;32m    393\u001b[0m         \u001b[39mself\u001b[39m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/federated/venv/lib/python3.9/site-packages/tensorflow_federated/python/common_libs/retrying.py:119\u001b[0m, in \u001b[0;36mretry.<locals>.retry_coro_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m    118\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m retry_on_exception_filter(e):\n\u001b[0;32m--> 119\u001b[0m     \u001b[39mraise\u001b[39;00m e\n\u001b[1;32m    120\u001b[0m   retry_wait_ms \u001b[39m=\u001b[39m \u001b[39mmin\u001b[39m(wait_max_ms, retry_wait_ms \u001b[39m*\u001b[39m wait_multiplier)\n\u001b[1;32m    121\u001b[0m   \u001b[39m# asyncio.sleep takes arguments in seconds.\u001b[39;00m\n",
      "File \u001b[0;32m~/federated/venv/lib/python3.9/site-packages/tensorflow_federated/python/common_libs/retrying.py:109\u001b[0m, in \u001b[0;36mretry.<locals>.retry_coro_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    107\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m    108\u001b[0m   \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 109\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mawait\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    110\u001b[0m     \u001b[39mif\u001b[39;00m retry_on_result_filter(result):\n\u001b[1;32m    111\u001b[0m       retry_wait_ms \u001b[39m=\u001b[39m \u001b[39mmin\u001b[39m(wait_max_ms, retry_wait_ms \u001b[39m*\u001b[39m wait_multiplier)\n",
      "File \u001b[0;32m~/federated/venv/lib/python3.9/site-packages/tensorflow_federated/python/core/impl/execution_contexts/async_execution_context.py:240\u001b[0m, in \u001b[0;36mAsyncExecutionContext.invoke\u001b[0;34m(self, comp, arg)\u001b[0m\n\u001b[1;32m    235\u001b[0m \u001b[39mif\u001b[39;00m arg \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    236\u001b[0m   arg \u001b[39m=\u001b[39m \u001b[39mawait\u001b[39;00m tracing\u001b[39m.\u001b[39mwrap_coroutine_in_current_trace_context(\n\u001b[1;32m    237\u001b[0m       _ingest(executor, arg, comp\u001b[39m.\u001b[39mtype_signature\u001b[39m.\u001b[39mparameter)\n\u001b[1;32m    238\u001b[0m   )\n\u001b[0;32m--> 240\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mawait\u001b[39;00m tracing\u001b[39m.\u001b[39mwrap_coroutine_in_current_trace_context(\n\u001b[1;32m    241\u001b[0m     _invoke(executor, comp, arg, result_type)\n\u001b[1;32m    242\u001b[0m )\n",
      "File \u001b[0;32m~/federated/venv/lib/python3.9/site-packages/tensorflow_federated/python/common_libs/tracing.py:406\u001b[0m, in \u001b[0;36mwrap_coroutine_in_current_trace_context.<locals>._wrapped\u001b[0;34m()\u001b[0m\n\u001b[1;32m    404\u001b[0m \u001b[39masync\u001b[39;00m \u001b[39mdef\u001b[39;00m \u001b[39m_wrapped\u001b[39m():\n\u001b[1;32m    405\u001b[0m   \u001b[39mwith\u001b[39;00m _with_span_yields(trace_span_yields):\n\u001b[0;32m--> 406\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mawait\u001b[39;00m coro\n",
      "File \u001b[0;32m~/federated/venv/lib/python3.9/site-packages/tensorflow_federated/python/core/impl/execution_contexts/async_execution_context.py:144\u001b[0m, in \u001b[0;36m_invoke\u001b[0;34m(executor, comp, arg, result_type)\u001b[0m\n\u001b[1;32m    142\u001b[0m   py_typecheck\u001b[39m.\u001b[39mcheck_type(arg, executor_value_base\u001b[39m.\u001b[39mExecutorValue)\n\u001b[1;32m    143\u001b[0m comp \u001b[39m=\u001b[39m \u001b[39mawait\u001b[39;00m executor\u001b[39m.\u001b[39mcreate_value(comp, comp\u001b[39m.\u001b[39mtype_signature)\n\u001b[0;32m--> 144\u001b[0m result \u001b[39m=\u001b[39m \u001b[39mawait\u001b[39;00m executor\u001b[39m.\u001b[39mcreate_call(comp, arg)\n\u001b[1;32m    145\u001b[0m py_typecheck\u001b[39m.\u001b[39mcheck_type(result, executor_value_base\u001b[39m.\u001b[39mExecutorValue)\n\u001b[1;32m    146\u001b[0m result_val \u001b[39m=\u001b[39m _unwrap(\u001b[39mawait\u001b[39;00m result\u001b[39m.\u001b[39mcompute())\n",
      "File \u001b[0;32m~/federated/venv/lib/python3.9/site-packages/tensorflow_federated/python/common_libs/tracing.py:207\u001b[0m, in \u001b[0;36mtrace.<locals>.async_trace\u001b[0;34m(*fn_args, **fn_kwargs)\u001b[0m\n\u001b[1;32m    204\u001b[0m \u001b[39m# Run the underlying function, recording the resulting value or exception\u001b[39;00m\n\u001b[1;32m    205\u001b[0m \u001b[39m# and passing it back to the span generator\u001b[39;00m\n\u001b[1;32m    206\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 207\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mawait\u001b[39;00m fn(\u001b[39m*\u001b[39mfn_args, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfn_kwargs)\n\u001b[1;32m    208\u001b[0m   completed \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    209\u001b[0m   \u001b[39mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/federated/venv/lib/python3.9/site-packages/tensorflow_federated/python/core/impl/executors/remote_executor.py:252\u001b[0m, in \u001b[0;36mRemoteExecutor.create_call\u001b[0;34m(self, comp, arg)\u001b[0m\n\u001b[1;32m    246\u001b[0m   py_typecheck\u001b[39m.\u001b[39mcheck_type(arg, RemoteValue)\n\u001b[1;32m    247\u001b[0m create_call_request \u001b[39m=\u001b[39m executor_pb2\u001b[39m.\u001b[39mCreateCallRequest(\n\u001b[1;32m    248\u001b[0m     executor\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_executor_id,\n\u001b[1;32m    249\u001b[0m     function_ref\u001b[39m=\u001b[39mcomp\u001b[39m.\u001b[39mreference,\n\u001b[1;32m    250\u001b[0m     argument_ref\u001b[39m=\u001b[39m(arg\u001b[39m.\u001b[39mreference \u001b[39mif\u001b[39;00m arg \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m),\n\u001b[1;32m    251\u001b[0m )\n\u001b[0;32m--> 252\u001b[0m response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_stub\u001b[39m.\u001b[39;49mcreate_call(create_call_request)\n\u001b[1;32m    253\u001b[0m py_typecheck\u001b[39m.\u001b[39mcheck_type(response, executor_pb2\u001b[39m.\u001b[39mCreateCallResponse)\n\u001b[1;32m    254\u001b[0m \u001b[39mreturn\u001b[39;00m RemoteValue(response\u001b[39m.\u001b[39mvalue_ref, comp\u001b[39m.\u001b[39mtype_signature\u001b[39m.\u001b[39mresult, \u001b[39mself\u001b[39m)\n",
      "File \u001b[0;32m~/federated/venv/lib/python3.9/site-packages/tensorflow_federated/python/core/impl/executors/remote_executor_grpc_stub.py:87\u001b[0m, in \u001b[0;36mRemoteExecutorGrpcStub.create_call\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcreate_call\u001b[39m(\n\u001b[1;32m     84\u001b[0m     \u001b[39mself\u001b[39m, request: executor_pb2\u001b[39m.\u001b[39mCreateCallRequest\n\u001b[1;32m     85\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m executor_pb2\u001b[39m.\u001b[39mCreateCallResponse:\n\u001b[1;32m     86\u001b[0m \u001b[39m  \u001b[39m\u001b[39m\"\"\"Dispatches a CreateCall gRPC.\"\"\"\u001b[39;00m\n\u001b[0;32m---> 87\u001b[0m   \u001b[39mreturn\u001b[39;00m _request(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_stub\u001b[39m.\u001b[39;49mCreateCall, request)\n",
      "File \u001b[0;32m~/federated/venv/lib/python3.9/site-packages/tensorflow_federated/python/common_libs/tracing.py:236\u001b[0m, in \u001b[0;36mtrace.<locals>.sync_trace\u001b[0;34m(*fn_args, **fn_kwargs)\u001b[0m\n\u001b[1;32m    234\u001b[0m completed \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m    235\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 236\u001b[0m   result \u001b[39m=\u001b[39m fn(\u001b[39m*\u001b[39;49mfn_args, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfn_kwargs)\n\u001b[1;32m    237\u001b[0m   completed \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    238\u001b[0m   \u001b[39mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/federated/venv/lib/python3.9/site-packages/tensorflow_federated/python/core/impl/executors/remote_executor_grpc_stub.py:40\u001b[0m, in \u001b[0;36m_request\u001b[0;34m(rpc_func, request)\u001b[0m\n\u001b[1;32m     38\u001b[0m   \u001b[39mraise\u001b[39;00m executors_errors\u001b[39m.\u001b[39mRetryableGRPCError(e)\n\u001b[1;32m     39\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m---> 40\u001b[0m   \u001b[39mraise\u001b[39;00m e\n",
      "File \u001b[0;32m~/federated/venv/lib/python3.9/site-packages/tensorflow_federated/python/core/impl/executors/remote_executor_grpc_stub.py:31\u001b[0m, in \u001b[0;36m_request\u001b[0;34m(rpc_func, request)\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[39mwith\u001b[39;00m tracing\u001b[39m.\u001b[39mwrap_rpc_in_trace_context():\n\u001b[1;32m     30\u001b[0m   \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 31\u001b[0m     \u001b[39mreturn\u001b[39;00m rpc_func(request)\n\u001b[1;32m     32\u001b[0m   \u001b[39mexcept\u001b[39;00m grpc\u001b[39m.\u001b[39mRpcError \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     33\u001b[0m     \u001b[39mif\u001b[39;00m (\n\u001b[1;32m     34\u001b[0m         \u001b[39misinstance\u001b[39m(e, grpc\u001b[39m.\u001b[39mCall)\n\u001b[1;32m     35\u001b[0m         \u001b[39mand\u001b[39;00m e\u001b[39m.\u001b[39mcode() \u001b[39min\u001b[39;00m executors_errors\u001b[39m.\u001b[39mget_grpc_retryable_error_codes()\n\u001b[1;32m     36\u001b[0m     ):\n",
      "File \u001b[0;32m~/federated/venv/lib/python3.9/site-packages/grpc/_channel.py:946\u001b[0m, in \u001b[0;36m_UnaryUnaryMultiCallable.__call__\u001b[0;34m(self, request, timeout, metadata, credentials, wait_for_ready, compression)\u001b[0m\n\u001b[1;32m    937\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m,\n\u001b[1;32m    938\u001b[0m              request,\n\u001b[1;32m    939\u001b[0m              timeout\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    942\u001b[0m              wait_for_ready\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    943\u001b[0m              compression\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m    944\u001b[0m     state, call, \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_blocking(request, timeout, metadata, credentials,\n\u001b[1;32m    945\u001b[0m                                   wait_for_ready, compression)\n\u001b[0;32m--> 946\u001b[0m     \u001b[39mreturn\u001b[39;00m _end_unary_response_blocking(state, call, \u001b[39mFalse\u001b[39;49;00m, \u001b[39mNone\u001b[39;49;00m)\n",
      "File \u001b[0;32m~/federated/venv/lib/python3.9/site-packages/grpc/_channel.py:849\u001b[0m, in \u001b[0;36m_end_unary_response_blocking\u001b[0;34m(state, call, with_call, deadline)\u001b[0m\n\u001b[1;32m    847\u001b[0m         \u001b[39mreturn\u001b[39;00m state\u001b[39m.\u001b[39mresponse\n\u001b[1;32m    848\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 849\u001b[0m     \u001b[39mraise\u001b[39;00m _InactiveRpcError(state)\n",
      "\u001b[0;31m_InactiveRpcError\u001b[0m: <_InactiveRpcError of RPC that terminated with:\n\tstatus = StatusCode.INTERNAL\n\tdetails = \"Failed to run computation: Op type not registered 'RegexSplitWithOffsets' in binary running on kilian-tf. Make sure the Op and Kernel are registered in the binary running in this process. Note that if you are loading a saved graph which used ops from tf.contrib, accessing (e.g.) `tf.contrib.resampler` should be done before importing the graph, as contrib ops are lazily registered when the module is first accessed.\n\t [[{{node MapDataset/_9}}]]\n\t [[root/1/Placeholder/DatasetFromGraph]] while evaluating local [_ovm25] in block locals [_ovm3,_ovm4,_ovm5,_ovm6,_ovm20,_ovm21,_ovm22,_ovm23,_ovm24,_ovm25,_ovm26,_ovm27,_ovm28,_ovm53,_ovm54,_ovm55,_ovm56,_ovm57,_ovm58,_ovm59,_ovm60,_ovm61,_ovm62,_ovm63,_ovm64,_ovm65,_ovm66,_ovm67,_ovm68,_ovm69,_ovm78,_ovm79,_ovm80,_ovm81,_ovm82,_ovm83,_ovm84,_ovm85,_ovm86,_ovm87,_ovm88,_ovm89]\"\n\tdebug_error_string = \"UNKNOWN:Error received from peer ipv6:%5B::1%5D:38263 {created_time:\"2023-05-23T10:12:50.801675196+00:00\", grpc_status:13, grpc_message:\"Failed to run computation: Op type not registered \\'RegexSplitWithOffsets\\' in binary running on kilian-tf. Make sure the Op and Kernel are registered in the binary running in this process. Note that if you are loading a saved graph which used ops from tf.contrib, accessing (e.g.) `tf.contrib.resampler` should be done before importing the graph, as contrib ops are lazily registered when the module is first accessed.\\n\\t [[{{node MapDataset/_9}}]]\\n\\t [[root/1/Placeholder/DatasetFromGraph]] while evaluating local [_ovm25] in block locals [_ovm3,_ovm4,_ovm5,_ovm6,_ovm20,_ovm21,_ovm22,_ovm23,_ovm24,_ovm25,_ovm26,_ovm27,_ovm28,_ovm53,_ovm54,_ovm55,_ovm56,_ovm57,_ovm58,_ovm59,_ovm60,_ovm61,_ovm62,_ovm63,_ovm64,_ovm65,_ovm66,_ovm67,_ovm68,_ovm69,_ovm78,_ovm79,_ovm80,_ovm81,_ovm82,_ovm83,_ovm84,_ovm85,_ovm86,_ovm87,_ovm88,_ovm89]\"}\"\n>"
     ]
    }
   ],
   "source": [
    "def get_iterative_process(noise, n_clients=0):\n",
    "    if noise == 0.0:\n",
    "        iterative_process = tff.learning.algorithms.build_weighted_fed_avg(\n",
    "            model_fn=model_tff,\n",
    "            client_optimizer_fn=lambda: tf.keras.optimizers.Adam(),\n",
    "            server_optimizer_fn=lambda: tf.keras.optimizers.SGD(learning_rate=1),\n",
    "            use_experimental_simulation_loop=True\n",
    "        )\n",
    "    else:\n",
    "        aggregation_factory = tff.learning.model_update_aggregator.dp_aggregator(noise, n_clients)\n",
    "        iterative_process = tff.learning.algorithms.build_weighted_fed_avg(\n",
    "            model_fn=model_tff,\n",
    "            client_optimizer_fn=lambda: tf.keras.optimizers.Adam(),\n",
    "            server_optimizer_fn=lambda: tf.keras.optimizers.SGD(learning_rate=1),\n",
    "            # model_update_aggregation_factory=aggregation_factory\n",
    "        )\n",
    "    return iterative_process\n",
    "\n",
    "Noise = 0.5\n",
    "total_clients = len(df.federation_level.unique())\n",
    "n_clients = len(df.federation_level.unique())\n",
    "tf.config.run_functions_eagerly(False)\n",
    "\n",
    "\n",
    "\n",
    "iterative_process = get_iterative_process(Noise, n_clients)\n",
    "state = iterative_process.initialize()\n",
    "state, metrics = iterative_process.next(state, train_data)\n",
    "\n",
    "# for round_num in range(4):\n",
    "#     state, metrics = iterative_process.next(state, train_data)\n",
    "#     print(f\"Round {round_num+1} - Train Loss: {metrics['loss']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ee9edcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q = n_clients/total_clients\n",
    "config = {'Q':Q,\n",
    "          'clients_per_round':int(n_clients),\n",
    "          'total_clients':total_clients,\n",
    "          'noise': Noise,\n",
    "          'batch_size':int(BATCH_SIZE),\n",
    "          'eval_client_size':len(glob('../Dataset/*/test/*/scaled/')),\n",
    "          'internal_epochs':int(NUM_EPOCHS)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "de01c73d",
   "metadata": {},
   "outputs": [],
   "source": [
    "nest_asyncio.apply()\n",
    "state = iterative_process.initialize()  \n",
    "NUM_ROUNDS = 125\n",
    "results = pd.DataFrame()\n",
    "unique_id = str(uuid.uuid4())[0:8]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3054735a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-22 16:01:00.581902: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-05-22 16:01:00.583379: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 1\n",
      "2023-05-22 16:01:00.583524: I tensorflow/core/grappler/clusters/single_machine.cc:358] Starting new session\n",
      "2023-05-22 16:01:00.583852: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-05-22 16:01:00.585016: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1956] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2023-05-22 16:01:00.651221: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-05-22 16:01:00.652512: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 1\n",
      "2023-05-22 16:01:00.652605: I tensorflow/core/grappler/clusters/single_machine.cc:358] Starting new session\n",
      "2023-05-22 16:01:00.652870: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-05-22 16:01:00.654037: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1956] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2023-05-22 16:01:00.660974: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-05-22 16:01:00.662176: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 1\n",
      "2023-05-22 16:01:00.662268: I tensorflow/core/grappler/clusters/single_machine.cc:358] Starting new session\n",
      "2023-05-22 16:01:00.662540: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-05-22 16:01:00.663700: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1956] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2023-05-22 16:01:00.673545: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-05-22 16:01:00.674734: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 1\n",
      "2023-05-22 16:01:00.674822: I tensorflow/core/grappler/clusters/single_machine.cc:358] Starting new session\n",
      "2023-05-22 16:01:00.675080: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-05-22 16:01:00.676230: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1956] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2023-05-22 16:01:00.687871: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-05-22 16:01:00.689056: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 1\n",
      "2023-05-22 16:01:00.689130: I tensorflow/core/grappler/clusters/single_machine.cc:358] Starting new session\n",
      "2023-05-22 16:01:00.689405: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-05-22 16:01:00.690562: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1956] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2023-05-22 16:01:00.706042: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-05-22 16:01:00.707270: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 1\n",
      "2023-05-22 16:01:00.707358: I tensorflow/core/grappler/clusters/single_machine.cc:358] Starting new session\n",
      "2023-05-22 16:01:00.707614: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-05-22 16:01:00.708768: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1956] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2023-05-22 16:01:00.709309: E tensorflow/core/grappler/grappler_item_builder.cc:430] Failed to detect the fetch node(s), skipping this input\n",
      "2023-05-22 16:01:00.711918: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-05-22 16:01:00.713088: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 1\n",
      "2023-05-22 16:01:00.713156: I tensorflow/core/grappler/clusters/single_machine.cc:358] Starting new session\n",
      "2023-05-22 16:01:00.713398: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-05-22 16:01:00.714551: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1956] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2023-05-22 16:01:00.715032: E tensorflow/core/grappler/grappler_item_builder.cc:430] Failed to detect the fetch node(s), skipping this input\n",
      "2023-05-22 16:01:00.717256: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-05-22 16:01:00.718453: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 1\n",
      "2023-05-22 16:01:00.718527: I tensorflow/core/grappler/clusters/single_machine.cc:358] Starting new session\n",
      "2023-05-22 16:01:00.718775: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-05-22 16:01:00.719929: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1956] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2023-05-22 16:01:00.720395: E tensorflow/core/grappler/grappler_item_builder.cc:430] Failed to detect the fetch node(s), skipping this input\n",
      "2023-05-22 16:01:00.721964: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-05-22 16:01:00.723150: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 1\n",
      "2023-05-22 16:01:00.723218: I tensorflow/core/grappler/clusters/single_machine.cc:358] Starting new session\n",
      "2023-05-22 16:01:00.723460: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-05-22 16:01:00.724603: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1956] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2023-05-22 16:01:00.725087: E tensorflow/core/grappler/grappler_item_builder.cc:430] Failed to detect the fetch node(s), skipping this input\n",
      "2023-05-22 16:01:00.727136: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-05-22 16:01:00.728295: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 1\n",
      "2023-05-22 16:01:00.728358: I tensorflow/core/grappler/clusters/single_machine.cc:358] Starting new session\n",
      "2023-05-22 16:01:00.728600: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-05-22 16:01:00.729752: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1956] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2023-05-22 16:01:00.732211: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-05-22 16:01:00.733389: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 1\n",
      "2023-05-22 16:01:00.733458: I tensorflow/core/grappler/clusters/single_machine.cc:358] Starting new session\n",
      "2023-05-22 16:01:00.733719: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-05-22 16:01:00.734872: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1956] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2023-05-22 16:01:00.739186: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-05-22 16:01:00.740369: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 1\n",
      "2023-05-22 16:01:00.740438: I tensorflow/core/grappler/clusters/single_machine.cc:358] Starting new session\n",
      "2023-05-22 16:01:00.740698: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-05-22 16:01:00.741853: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1956] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2023-05-22 16:01:00.745983: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-05-22 16:01:00.747150: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 1\n",
      "2023-05-22 16:01:00.747218: I tensorflow/core/grappler/clusters/single_machine.cc:358] Starting new session\n",
      "2023-05-22 16:01:00.747453: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-05-22 16:01:00.748607: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1956] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2023-05-22 16:01:00.749090: E tensorflow/core/grappler/grappler_item_builder.cc:430] Failed to detect the fetch node(s), skipping this input\n",
      "2023-05-22 16:01:00.753155: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-05-22 16:01:00.754386: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 1\n",
      "2023-05-22 16:01:00.754457: I tensorflow/core/grappler/clusters/single_machine.cc:358] Starting new session\n",
      "2023-05-22 16:01:00.754689: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-05-22 16:01:00.755846: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1956] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2023-05-22 16:01:00.762473: W tensorflow/core/grappler/optimizers/loop_optimizer.cc:907] Skipping loop optimization for Merge node with control input: StatefulPartitionedCall/cond/branch_executed/_16\n",
      "2023-05-22 16:01:01.005743: E tensorflow_federated/cc/core/impl/executors/tensorflow_executor.cc:711] Failed to run computation: No OpKernel was registered to support Op 'EagerPyFunc' used by {{node EagerPyFunc}} with these attrs: [is_async=false, Tin=[DT_STRING, DT_INT64], token=\"pyfunc_14\", Tout=[DT_INT32, DT_INT32]]\n",
      "Registered devices: [CPU]\n",
      "Registered kernels:\n",
      "  <no registered kernels>\n",
      "\n",
      "\t [[EagerPyFunc]]\n",
      "\t [[StatefulPartitionedCall/ReduceDataset]]\n",
      "2023-05-22 16:01:01.005825: E tensorflow_federated/cc/core/impl/executors/tensorflow_executor.cc:711] Failed to run computation: No OpKernel was registered to support Op 'EagerPyFunc' used by {{node EagerPyFunc}} with these attrs: [Tout=[DT_INT32, DT_INT32], Tin=[DT_STRING, DT_INT64], token=\"pyfunc_6\", is_async=false]\n",
      "Registered devices: [CPU]\n",
      "Registered kernels:\n",
      "  <no registered kernels>\n",
      "\n",
      "\t [[EagerPyFunc]]\n",
      "\t [[StatefulPartitionedCall/ReduceDataset]]\n",
      "2023-05-22 16:01:01.026477: E tensorflow_federated/cc/core/impl/executors/tensorflow_executor.cc:711] Failed to run computation: No OpKernel was registered to support Op 'EagerPyFunc' used by {{node EagerPyFunc}} with these attrs: [Tout=[DT_INT32, DT_INT32], Tin=[DT_STRING, DT_INT64], token=\"pyfunc_3\", is_async=false]\n",
      "Registered devices: [CPU]\n",
      "Registered kernels:\n",
      "  <no registered kernels>\n",
      "\n",
      "\t [[EagerPyFunc]]\n",
      "\t [[StatefulPartitionedCall/ReduceDataset]]\n",
      "2023-05-22 16:01:01.046562: E tensorflow_federated/cc/core/impl/executors/tensorflow_executor.cc:711] Failed to run computation: No OpKernel was registered to support Op 'EagerPyFunc' used by {{node EagerPyFunc}} with these attrs: [Tout=[DT_INT32, DT_INT32], token=\"pyfunc_10\", Tin=[DT_STRING, DT_INT64], is_async=false]\n",
      "Registered devices: [CPU]\n",
      "Registered kernels:\n",
      "  <no registered kernels>\n",
      "\n",
      "\t [[EagerPyFunc]]\n",
      "\t [[StatefulPartitionedCall/ReduceDataset]]\n",
      "2023-05-22 16:01:01.047170: E tensorflow_federated/cc/core/impl/executors/tensorflow_executor.cc:711] Failed to run computation: No OpKernel was registered to support Op 'EagerPyFunc' used by {{node EagerPyFunc}} with these attrs: [Tin=[DT_STRING, DT_INT64], Tout=[DT_INT32, DT_INT32], token=\"pyfunc_21\", is_async=false]\n",
      "Registered devices: [CPU]\n",
      "Registered kernels:\n",
      "  <no registered kernels>\n",
      "\n",
      "\t [[EagerPyFunc]]\n",
      "\t [[StatefulPartitionedCall/ReduceDataset]]\n",
      "2023-05-22 16:01:01.058490: E tensorflow_federated/cc/core/impl/executors/tensorflow_executor.cc:711] Failed to run computation: No OpKernel was registered to support Op 'EagerPyFunc' used by {{node EagerPyFunc}} with these attrs: [Tout=[DT_INT32, DT_INT32], Tin=[DT_STRING, DT_INT64], token=\"pyfunc_15\", is_async=false]\n",
      "Registered devices: [CPU]\n",
      "Registered kernels:\n",
      "  <no registered kernels>\n",
      "\n",
      "\t [[EagerPyFunc]]\n",
      "\t [[StatefulPartitionedCall/ReduceDataset]]\n",
      "2023-05-22 16:01:01.070173: E tensorflow_federated/cc/core/impl/executors/tensorflow_executor.cc:711] Failed to run computation: No OpKernel was registered to support Op 'EagerPyFunc' used by {{node EagerPyFunc}} with these attrs: [Tout=[DT_INT32, DT_INT32], token=\"pyfunc_8\", Tin=[DT_STRING, DT_INT64], is_async=false]\n",
      "Registered devices: [CPU]\n",
      "Registered kernels:\n",
      "  <no registered kernels>\n",
      "\n",
      "\t [[EagerPyFunc]]\n",
      "\t [[StatefulPartitionedCall/ReduceDataset]]\n",
      "2023-05-22 16:01:01.078802: E tensorflow_federated/cc/core/impl/executors/tensorflow_executor.cc:711] Failed to run computation: No OpKernel was registered to support Op 'EagerPyFunc' used by {{node EagerPyFunc}} with these attrs: [is_async=false, Tin=[DT_STRING, DT_INT64], Tout=[DT_INT32, DT_INT32], token=\"pyfunc_4\"]\n",
      "Registered devices: [CPU]\n",
      "Registered kernels:\n",
      "  <no registered kernels>\n",
      "\n",
      "\t [[EagerPyFunc]]\n",
      "\t [[StatefulPartitionedCall/ReduceDataset]]\n",
      "2023-05-22 16:01:01.097949: E tensorflow_federated/cc/core/impl/executors/tensorflow_executor.cc:711] Failed to run computation: No OpKernel was registered to support Op 'EagerPyFunc' used by {{node EagerPyFunc}} with these attrs: [is_async=false, Tout=[DT_INT32, DT_INT32], Tin=[DT_STRING, DT_INT64], token=\"pyfunc_19\"]\n",
      "Registered devices: [CPU]\n",
      "Registered kernels:\n",
      "  <no registered kernels>\n",
      "\n",
      "\t [[EagerPyFunc]]\n",
      "\t [[StatefulPartitionedCall/ReduceDataset]]\n",
      "2023-05-22 16:01:01.103955: E tensorflow_federated/cc/core/impl/executors/tensorflow_executor.cc:711] Failed to run computation: No OpKernel was registered to support Op 'EagerPyFunc' used by {{node EagerPyFunc}} with these attrs: [Tin=[DT_STRING, DT_INT64], token=\"pyfunc_16\", is_async=false, Tout=[DT_INT32, DT_INT32]]\n",
      "Registered devices: [CPU]\n",
      "Registered kernels:\n",
      "  <no registered kernels>\n",
      "\n",
      "\t [[EagerPyFunc]]\n",
      "\t [[StatefulPartitionedCall/ReduceDataset]]\n",
      "2023-05-22 16:01:01.119358: E tensorflow_federated/cc/core/impl/executors/tensorflow_executor.cc:711] Failed to run computation: No OpKernel was registered to support Op 'EagerPyFunc' used by {{node EagerPyFunc}} with these attrs: [is_async=false, Tin=[DT_STRING, DT_INT64], Tout=[DT_INT32, DT_INT32], token=\"pyfunc_22\"]\n",
      "Registered devices: [CPU]\n",
      "Registered kernels:\n",
      "  <no registered kernels>\n",
      "\n",
      "\t [[EagerPyFunc]]\n",
      "\t [[StatefulPartitionedCall/ReduceDataset]]\n",
      "2023-05-22 16:01:01.126174: E tensorflow_federated/cc/core/impl/executors/tensorflow_executor.cc:711] Failed to run computation: No OpKernel was registered to support Op 'EagerPyFunc' used by {{node EagerPyFunc}} with these attrs: [token=\"pyfunc_20\", is_async=false, Tout=[DT_INT32, DT_INT32], Tin=[DT_STRING, DT_INT64]]\n",
      "Registered devices: [CPU]\n",
      "Registered kernels:\n",
      "  <no registered kernels>\n",
      "\n",
      "\t [[EagerPyFunc]]\n",
      "\t [[StatefulPartitionedCall/ReduceDataset]]\n",
      "2023-05-22 16:01:01.132735: E tensorflow_federated/cc/core/impl/executors/tensorflow_executor.cc:711] Failed to run computation: No OpKernel was registered to support Op 'EagerPyFunc' used by {{node EagerPyFunc}} with these attrs: [is_async=false, Tout=[DT_INT32, DT_INT32], token=\"pyfunc_9\", Tin=[DT_STRING, DT_INT64]]\n",
      "Registered devices: [CPU]\n",
      "Registered kernels:\n",
      "  <no registered kernels>\n",
      "\n",
      "\t [[EagerPyFunc]]\n",
      "\t [[StatefulPartitionedCall/ReduceDataset]]\n",
      "2023-05-22 16:01:01.141738: E tensorflow_federated/cc/core/impl/executors/tensorflow_executor.cc:711] Failed to run computation: No OpKernel was registered to support Op 'EagerPyFunc' used by {{node EagerPyFunc}} with these attrs: [token=\"pyfunc_17\", Tin=[DT_STRING, DT_INT64], Tout=[DT_INT32, DT_INT32], is_async=false]\n",
      "Registered devices: [CPU]\n",
      "Registered kernels:\n",
      "  <no registered kernels>\n",
      "\n",
      "\t [[EagerPyFunc]]\n",
      "\t [[StatefulPartitionedCall/ReduceDataset]]\n",
      "2023-05-22 16:01:01.146671: E tensorflow_federated/cc/core/impl/executors/tensorflow_executor.cc:711] Failed to run computation: No OpKernel was registered to support Op 'EagerPyFunc' used by {{node EagerPyFunc}} with these attrs: [is_async=false, token=\"pyfunc_13\", Tin=[DT_STRING, DT_INT64], Tout=[DT_INT32, DT_INT32]]\n",
      "Registered devices: [CPU]\n",
      "Registered kernels:\n",
      "  <no registered kernels>\n",
      "\n",
      "\t [[EagerPyFunc]]\n",
      "\t [[StatefulPartitionedCall/ReduceDataset]]\n",
      "2023-05-22 16:01:01.155349: E tensorflow_federated/cc/core/impl/executors/tensorflow_executor.cc:711] Failed to run computation: No OpKernel was registered to support Op 'EagerPyFunc' used by {{node EagerPyFunc}} with these attrs: [is_async=false, Tin=[DT_STRING, DT_INT64], token=\"pyfunc_5\", Tout=[DT_INT32, DT_INT32]]\n",
      "Registered devices: [CPU]\n",
      "Registered kernels:\n",
      "  <no registered kernels>\n",
      "\n",
      "\t [[EagerPyFunc]]\n",
      "\t [[StatefulPartitionedCall/ReduceDataset]]\n",
      "2023-05-22 16:01:01.158663: E tensorflow_federated/cc/core/impl/executors/tensorflow_executor.cc:711] Failed to run computation: No OpKernel was registered to support Op 'EagerPyFunc' used by {{node EagerPyFunc}} with these attrs: [Tin=[DT_STRING, DT_INT64], is_async=false, Tout=[DT_INT32, DT_INT32], token=\"pyfunc_11\"]\n",
      "Registered devices: [CPU]\n",
      "Registered kernels:\n",
      "  <no registered kernels>\n",
      "\n",
      "\t [[EagerPyFunc]]\n",
      "\t [[StatefulPartitionedCall/ReduceDataset]]\n",
      "2023-05-22 16:01:01.165516: E tensorflow_federated/cc/core/impl/executors/tensorflow_executor.cc:711] Failed to run computation: No OpKernel was registered to support Op 'EagerPyFunc' used by {{node EagerPyFunc}} with these attrs: [Tout=[DT_INT32, DT_INT32], is_async=false, token=\"pyfunc_7\", Tin=[DT_STRING, DT_INT64]]\n",
      "Registered devices: [CPU]\n",
      "Registered kernels:\n",
      "  <no registered kernels>\n",
      "\n",
      "\t [[EagerPyFunc]]\n",
      "\t [[StatefulPartitionedCall/ReduceDataset]]\n",
      "2023-05-22 16:01:01.169479: E tensorflow_federated/cc/core/impl/executors/tensorflow_executor.cc:711] Failed to run computation: No OpKernel was registered to support Op 'EagerPyFunc' used by {{node EagerPyFunc}} with these attrs: [Tout=[DT_INT32, DT_INT32], is_async=false, token=\"pyfunc_12\", Tin=[DT_STRING, DT_INT64]]\n",
      "Registered devices: [CPU]\n",
      "Registered kernels:\n",
      "  <no registered kernels>\n",
      "\n",
      "\t [[EagerPyFunc]]\n",
      "\t [[StatefulPartitionedCall/ReduceDataset]]\n",
      "2023-05-22 16:01:01.173586: E tensorflow_federated/cc/core/impl/executors/tensorflow_executor.cc:711] Failed to run computation: No OpKernel was registered to support Op 'EagerPyFunc' used by {{node EagerPyFunc}} with these attrs: [token=\"pyfunc_18\", is_async=false, Tin=[DT_STRING, DT_INT64], Tout=[DT_INT32, DT_INT32]]\n",
      "Registered devices: [CPU]\n",
      "Registered kernels:\n",
      "  <no registered kernels>\n",
      "\n",
      "\t [[EagerPyFunc]]\n",
      "\t [[StatefulPartitionedCall/ReduceDataset]]\n"
     ]
    },
    {
     "ename": "_InactiveRpcError",
     "evalue": "<_InactiveRpcError of RPC that terminated with:\n\tstatus = StatusCode.INTERNAL\n\tdetails = \"Failed to run computation: No OpKernel was registered to support Op 'EagerPyFunc' used by {{node EagerPyFunc}} with these attrs: [Tout=[DT_INT32, DT_INT32], Tin=[DT_STRING, DT_INT64], token=\"pyfunc_3\", is_async=false]\nRegistered devices: [CPU]\nRegistered kernels:\n  <no registered kernels>\n\n\t [[EagerPyFunc]]\n\t [[StatefulPartitionedCall/ReduceDataset]] while evaluating local [_ern25] in block locals [_ern3,_ern4,_ern5,_ern6,_ern20,_ern21,_ern22,_ern23,_ern24,_ern25,_ern26,_ern27,_ern28,_ern53,_ern54,_ern55,_ern56,_ern57,_ern58,_ern59,_ern60,_ern61,_ern62,_ern63,_ern64,_ern65,_ern66,_ern67,_ern68,_ern69,_ern78,_ern79,_ern80,_ern81,_ern82,_ern83,_ern84,_ern85,_ern86,_ern87,_ern88,_ern89]\"\n\tdebug_error_string = \"UNKNOWN:Error received from peer ipv6:%5B::1%5D:37639 {created_time:\"2023-05-22T16:01:01.031072298+00:00\", grpc_status:13, grpc_message:\"Failed to run computation: No OpKernel was registered to support Op \\'EagerPyFunc\\' used by {{node EagerPyFunc}} with these attrs: [Tout=[DT_INT32, DT_INT32], Tin=[DT_STRING, DT_INT64], token=\\\"pyfunc_3\\\", is_async=false]\\nRegistered devices: [CPU]\\nRegistered kernels:\\n  <no registered kernels>\\n\\n\\t [[EagerPyFunc]]\\n\\t [[StatefulPartitionedCall/ReduceDataset]] while evaluating local [_ern25] in block locals [_ern3,_ern4,_ern5,_ern6,_ern20,_ern21,_ern22,_ern23,_ern24,_ern25,_ern26,_ern27,_ern28,_ern53,_ern54,_ern55,_ern56,_ern57,_ern58,_ern59,_ern60,_ern61,_ern62,_ern63,_ern64,_ern65,_ern66,_ern67,_ern68,_ern69,_ern78,_ern79,_ern80,_ern81,_ern82,_ern83,_ern84,_ern85,_ern86,_ern87,_ern88,_ern89]\"}\"\n>",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31m_InactiveRpcError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m sampled_train_data \u001b[39m=\u001b[39m [train_data\u001b[39m.\u001b[39mcreate_tf_dataset_for_client(client_id) \u001b[39mfor\u001b[39;00m client_id \u001b[39min\u001b[39;00m train_data\u001b[39m.\u001b[39mclient_ids]\n\u001b[0;32m----> 2\u001b[0m state, metrics \u001b[39m=\u001b[39m iterative_process\u001b[39m.\u001b[39;49mnext(state, sampled_train_data)\n",
      "File \u001b[0;32m~/federated/venv/lib/python3.9/site-packages/tensorflow_federated/python/core/impl/computation/computation_impl.py:139\u001b[0m, in \u001b[0;36mConcreteComputation.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    137\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    138\u001b[0m   arg \u001b[39m=\u001b[39m function_utils\u001b[39m.\u001b[39mpack_args(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_type_signature\u001b[39m.\u001b[39mparameter, args, kwargs)\n\u001b[0;32m--> 139\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_context_stack\u001b[39m.\u001b[39;49mcurrent\u001b[39m.\u001b[39;49minvoke(\u001b[39mself\u001b[39;49m, arg)\n",
      "File \u001b[0;32m~/federated/venv/lib/python3.9/site-packages/tensorflow_federated/python/core/impl/execution_contexts/sync_execution_context.py:65\u001b[0m, in \u001b[0;36mSyncExecutionContext.invoke\u001b[0;34m(self, comp, arg)\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39minvoke\u001b[39m(\u001b[39mself\u001b[39m, comp, arg):\n\u001b[0;32m---> 65\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_async_runner\u001b[39m.\u001b[39;49mrun_coro_and_return_result(\n\u001b[1;32m     66\u001b[0m       \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_async_context\u001b[39m.\u001b[39;49minvoke(comp, arg)\n\u001b[1;32m     67\u001b[0m   )\n",
      "File \u001b[0;32m~/federated/venv/lib/python3.9/site-packages/tensorflow_federated/python/common_libs/async_utils.py:224\u001b[0m, in \u001b[0;36mAsyncThreadRunner.run_coro_and_return_result\u001b[0;34m(self, coro)\u001b[0m\n\u001b[1;32m    222\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Runs coroutine in the managed event loop, returning the result.\"\"\"\u001b[39;00m\n\u001b[1;32m    223\u001b[0m future \u001b[39m=\u001b[39m asyncio\u001b[39m.\u001b[39mrun_coroutine_threadsafe(coro, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_event_loop)\n\u001b[0;32m--> 224\u001b[0m \u001b[39mreturn\u001b[39;00m future\u001b[39m.\u001b[39;49mresult()\n",
      "File \u001b[0;32m/usr/lib/python3.9/concurrent/futures/_base.py:445\u001b[0m, in \u001b[0;36mFuture.result\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    443\u001b[0m     \u001b[39mraise\u001b[39;00m CancelledError()\n\u001b[1;32m    444\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_state \u001b[39m==\u001b[39m FINISHED:\n\u001b[0;32m--> 445\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m__get_result()\n\u001b[1;32m    446\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    447\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTimeoutError\u001b[39;00m()\n",
      "File \u001b[0;32m/usr/lib/python3.9/concurrent/futures/_base.py:390\u001b[0m, in \u001b[0;36mFuture.__get_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    388\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_exception:\n\u001b[1;32m    389\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 390\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_exception\n\u001b[1;32m    391\u001b[0m     \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m    392\u001b[0m         \u001b[39m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[1;32m    393\u001b[0m         \u001b[39mself\u001b[39m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/federated/venv/lib/python3.9/site-packages/tensorflow_federated/python/common_libs/retrying.py:119\u001b[0m, in \u001b[0;36mretry.<locals>.retry_coro_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m    118\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m retry_on_exception_filter(e):\n\u001b[0;32m--> 119\u001b[0m     \u001b[39mraise\u001b[39;00m e\n\u001b[1;32m    120\u001b[0m   retry_wait_ms \u001b[39m=\u001b[39m \u001b[39mmin\u001b[39m(wait_max_ms, retry_wait_ms \u001b[39m*\u001b[39m wait_multiplier)\n\u001b[1;32m    121\u001b[0m   \u001b[39m# asyncio.sleep takes arguments in seconds.\u001b[39;00m\n",
      "File \u001b[0;32m~/federated/venv/lib/python3.9/site-packages/tensorflow_federated/python/common_libs/retrying.py:109\u001b[0m, in \u001b[0;36mretry.<locals>.retry_coro_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    107\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m    108\u001b[0m   \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 109\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mawait\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    110\u001b[0m     \u001b[39mif\u001b[39;00m retry_on_result_filter(result):\n\u001b[1;32m    111\u001b[0m       retry_wait_ms \u001b[39m=\u001b[39m \u001b[39mmin\u001b[39m(wait_max_ms, retry_wait_ms \u001b[39m*\u001b[39m wait_multiplier)\n",
      "File \u001b[0;32m~/federated/venv/lib/python3.9/site-packages/tensorflow_federated/python/core/impl/execution_contexts/async_execution_context.py:240\u001b[0m, in \u001b[0;36mAsyncExecutionContext.invoke\u001b[0;34m(self, comp, arg)\u001b[0m\n\u001b[1;32m    235\u001b[0m \u001b[39mif\u001b[39;00m arg \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    236\u001b[0m   arg \u001b[39m=\u001b[39m \u001b[39mawait\u001b[39;00m tracing\u001b[39m.\u001b[39mwrap_coroutine_in_current_trace_context(\n\u001b[1;32m    237\u001b[0m       _ingest(executor, arg, comp\u001b[39m.\u001b[39mtype_signature\u001b[39m.\u001b[39mparameter)\n\u001b[1;32m    238\u001b[0m   )\n\u001b[0;32m--> 240\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mawait\u001b[39;00m tracing\u001b[39m.\u001b[39mwrap_coroutine_in_current_trace_context(\n\u001b[1;32m    241\u001b[0m     _invoke(executor, comp, arg, result_type)\n\u001b[1;32m    242\u001b[0m )\n",
      "File \u001b[0;32m~/federated/venv/lib/python3.9/site-packages/tensorflow_federated/python/common_libs/tracing.py:406\u001b[0m, in \u001b[0;36mwrap_coroutine_in_current_trace_context.<locals>._wrapped\u001b[0;34m()\u001b[0m\n\u001b[1;32m    404\u001b[0m \u001b[39masync\u001b[39;00m \u001b[39mdef\u001b[39;00m \u001b[39m_wrapped\u001b[39m():\n\u001b[1;32m    405\u001b[0m   \u001b[39mwith\u001b[39;00m _with_span_yields(trace_span_yields):\n\u001b[0;32m--> 406\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mawait\u001b[39;00m coro\n",
      "File \u001b[0;32m~/federated/venv/lib/python3.9/site-packages/tensorflow_federated/python/core/impl/execution_contexts/async_execution_context.py:144\u001b[0m, in \u001b[0;36m_invoke\u001b[0;34m(executor, comp, arg, result_type)\u001b[0m\n\u001b[1;32m    142\u001b[0m   py_typecheck\u001b[39m.\u001b[39mcheck_type(arg, executor_value_base\u001b[39m.\u001b[39mExecutorValue)\n\u001b[1;32m    143\u001b[0m comp \u001b[39m=\u001b[39m \u001b[39mawait\u001b[39;00m executor\u001b[39m.\u001b[39mcreate_value(comp, comp\u001b[39m.\u001b[39mtype_signature)\n\u001b[0;32m--> 144\u001b[0m result \u001b[39m=\u001b[39m \u001b[39mawait\u001b[39;00m executor\u001b[39m.\u001b[39mcreate_call(comp, arg)\n\u001b[1;32m    145\u001b[0m py_typecheck\u001b[39m.\u001b[39mcheck_type(result, executor_value_base\u001b[39m.\u001b[39mExecutorValue)\n\u001b[1;32m    146\u001b[0m result_val \u001b[39m=\u001b[39m _unwrap(\u001b[39mawait\u001b[39;00m result\u001b[39m.\u001b[39mcompute())\n",
      "File \u001b[0;32m~/federated/venv/lib/python3.9/site-packages/tensorflow_federated/python/common_libs/tracing.py:207\u001b[0m, in \u001b[0;36mtrace.<locals>.async_trace\u001b[0;34m(*fn_args, **fn_kwargs)\u001b[0m\n\u001b[1;32m    204\u001b[0m \u001b[39m# Run the underlying function, recording the resulting value or exception\u001b[39;00m\n\u001b[1;32m    205\u001b[0m \u001b[39m# and passing it back to the span generator\u001b[39;00m\n\u001b[1;32m    206\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 207\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mawait\u001b[39;00m fn(\u001b[39m*\u001b[39mfn_args, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfn_kwargs)\n\u001b[1;32m    208\u001b[0m   completed \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    209\u001b[0m   \u001b[39mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/federated/venv/lib/python3.9/site-packages/tensorflow_federated/python/core/impl/executors/remote_executor.py:252\u001b[0m, in \u001b[0;36mRemoteExecutor.create_call\u001b[0;34m(self, comp, arg)\u001b[0m\n\u001b[1;32m    246\u001b[0m   py_typecheck\u001b[39m.\u001b[39mcheck_type(arg, RemoteValue)\n\u001b[1;32m    247\u001b[0m create_call_request \u001b[39m=\u001b[39m executor_pb2\u001b[39m.\u001b[39mCreateCallRequest(\n\u001b[1;32m    248\u001b[0m     executor\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_executor_id,\n\u001b[1;32m    249\u001b[0m     function_ref\u001b[39m=\u001b[39mcomp\u001b[39m.\u001b[39mreference,\n\u001b[1;32m    250\u001b[0m     argument_ref\u001b[39m=\u001b[39m(arg\u001b[39m.\u001b[39mreference \u001b[39mif\u001b[39;00m arg \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m),\n\u001b[1;32m    251\u001b[0m )\n\u001b[0;32m--> 252\u001b[0m response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_stub\u001b[39m.\u001b[39;49mcreate_call(create_call_request)\n\u001b[1;32m    253\u001b[0m py_typecheck\u001b[39m.\u001b[39mcheck_type(response, executor_pb2\u001b[39m.\u001b[39mCreateCallResponse)\n\u001b[1;32m    254\u001b[0m \u001b[39mreturn\u001b[39;00m RemoteValue(response\u001b[39m.\u001b[39mvalue_ref, comp\u001b[39m.\u001b[39mtype_signature\u001b[39m.\u001b[39mresult, \u001b[39mself\u001b[39m)\n",
      "File \u001b[0;32m~/federated/venv/lib/python3.9/site-packages/tensorflow_federated/python/core/impl/executors/remote_executor_grpc_stub.py:87\u001b[0m, in \u001b[0;36mRemoteExecutorGrpcStub.create_call\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcreate_call\u001b[39m(\n\u001b[1;32m     84\u001b[0m     \u001b[39mself\u001b[39m, request: executor_pb2\u001b[39m.\u001b[39mCreateCallRequest\n\u001b[1;32m     85\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m executor_pb2\u001b[39m.\u001b[39mCreateCallResponse:\n\u001b[1;32m     86\u001b[0m \u001b[39m  \u001b[39m\u001b[39m\"\"\"Dispatches a CreateCall gRPC.\"\"\"\u001b[39;00m\n\u001b[0;32m---> 87\u001b[0m   \u001b[39mreturn\u001b[39;00m _request(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_stub\u001b[39m.\u001b[39;49mCreateCall, request)\n",
      "File \u001b[0;32m~/federated/venv/lib/python3.9/site-packages/tensorflow_federated/python/common_libs/tracing.py:236\u001b[0m, in \u001b[0;36mtrace.<locals>.sync_trace\u001b[0;34m(*fn_args, **fn_kwargs)\u001b[0m\n\u001b[1;32m    234\u001b[0m completed \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m    235\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 236\u001b[0m   result \u001b[39m=\u001b[39m fn(\u001b[39m*\u001b[39;49mfn_args, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfn_kwargs)\n\u001b[1;32m    237\u001b[0m   completed \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    238\u001b[0m   \u001b[39mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/federated/venv/lib/python3.9/site-packages/tensorflow_federated/python/core/impl/executors/remote_executor_grpc_stub.py:40\u001b[0m, in \u001b[0;36m_request\u001b[0;34m(rpc_func, request)\u001b[0m\n\u001b[1;32m     38\u001b[0m   \u001b[39mraise\u001b[39;00m executors_errors\u001b[39m.\u001b[39mRetryableGRPCError(e)\n\u001b[1;32m     39\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m---> 40\u001b[0m   \u001b[39mraise\u001b[39;00m e\n",
      "File \u001b[0;32m~/federated/venv/lib/python3.9/site-packages/tensorflow_federated/python/core/impl/executors/remote_executor_grpc_stub.py:31\u001b[0m, in \u001b[0;36m_request\u001b[0;34m(rpc_func, request)\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[39mwith\u001b[39;00m tracing\u001b[39m.\u001b[39mwrap_rpc_in_trace_context():\n\u001b[1;32m     30\u001b[0m   \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 31\u001b[0m     \u001b[39mreturn\u001b[39;00m rpc_func(request)\n\u001b[1;32m     32\u001b[0m   \u001b[39mexcept\u001b[39;00m grpc\u001b[39m.\u001b[39mRpcError \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     33\u001b[0m     \u001b[39mif\u001b[39;00m (\n\u001b[1;32m     34\u001b[0m         \u001b[39misinstance\u001b[39m(e, grpc\u001b[39m.\u001b[39mCall)\n\u001b[1;32m     35\u001b[0m         \u001b[39mand\u001b[39;00m e\u001b[39m.\u001b[39mcode() \u001b[39min\u001b[39;00m executors_errors\u001b[39m.\u001b[39mget_grpc_retryable_error_codes()\n\u001b[1;32m     36\u001b[0m     ):\n",
      "File \u001b[0;32m~/federated/venv/lib/python3.9/site-packages/grpc/_channel.py:946\u001b[0m, in \u001b[0;36m_UnaryUnaryMultiCallable.__call__\u001b[0;34m(self, request, timeout, metadata, credentials, wait_for_ready, compression)\u001b[0m\n\u001b[1;32m    937\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m,\n\u001b[1;32m    938\u001b[0m              request,\n\u001b[1;32m    939\u001b[0m              timeout\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    942\u001b[0m              wait_for_ready\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    943\u001b[0m              compression\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m    944\u001b[0m     state, call, \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_blocking(request, timeout, metadata, credentials,\n\u001b[1;32m    945\u001b[0m                                   wait_for_ready, compression)\n\u001b[0;32m--> 946\u001b[0m     \u001b[39mreturn\u001b[39;00m _end_unary_response_blocking(state, call, \u001b[39mFalse\u001b[39;49;00m, \u001b[39mNone\u001b[39;49;00m)\n",
      "File \u001b[0;32m~/federated/venv/lib/python3.9/site-packages/grpc/_channel.py:849\u001b[0m, in \u001b[0;36m_end_unary_response_blocking\u001b[0;34m(state, call, with_call, deadline)\u001b[0m\n\u001b[1;32m    847\u001b[0m         \u001b[39mreturn\u001b[39;00m state\u001b[39m.\u001b[39mresponse\n\u001b[1;32m    848\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 849\u001b[0m     \u001b[39mraise\u001b[39;00m _InactiveRpcError(state)\n",
      "\u001b[0;31m_InactiveRpcError\u001b[0m: <_InactiveRpcError of RPC that terminated with:\n\tstatus = StatusCode.INTERNAL\n\tdetails = \"Failed to run computation: No OpKernel was registered to support Op 'EagerPyFunc' used by {{node EagerPyFunc}} with these attrs: [Tout=[DT_INT32, DT_INT32], Tin=[DT_STRING, DT_INT64], token=\"pyfunc_3\", is_async=false]\nRegistered devices: [CPU]\nRegistered kernels:\n  <no registered kernels>\n\n\t [[EagerPyFunc]]\n\t [[StatefulPartitionedCall/ReduceDataset]] while evaluating local [_ern25] in block locals [_ern3,_ern4,_ern5,_ern6,_ern20,_ern21,_ern22,_ern23,_ern24,_ern25,_ern26,_ern27,_ern28,_ern53,_ern54,_ern55,_ern56,_ern57,_ern58,_ern59,_ern60,_ern61,_ern62,_ern63,_ern64,_ern65,_ern66,_ern67,_ern68,_ern69,_ern78,_ern79,_ern80,_ern81,_ern82,_ern83,_ern84,_ern85,_ern86,_ern87,_ern88,_ern89]\"\n\tdebug_error_string = \"UNKNOWN:Error received from peer ipv6:%5B::1%5D:37639 {created_time:\"2023-05-22T16:01:01.031072298+00:00\", grpc_status:13, grpc_message:\"Failed to run computation: No OpKernel was registered to support Op \\'EagerPyFunc\\' used by {{node EagerPyFunc}} with these attrs: [Tout=[DT_INT32, DT_INT32], Tin=[DT_STRING, DT_INT64], token=\\\"pyfunc_3\\\", is_async=false]\\nRegistered devices: [CPU]\\nRegistered kernels:\\n  <no registered kernels>\\n\\n\\t [[EagerPyFunc]]\\n\\t [[StatefulPartitionedCall/ReduceDataset]] while evaluating local [_ern25] in block locals [_ern3,_ern4,_ern5,_ern6,_ern20,_ern21,_ern22,_ern23,_ern24,_ern25,_ern26,_ern27,_ern28,_ern53,_ern54,_ern55,_ern56,_ern57,_ern58,_ern59,_ern60,_ern61,_ern62,_ern63,_ern64,_ern65,_ern66,_ern67,_ern68,_ern69,_ern78,_ern79,_ern80,_ern81,_ern82,_ern83,_ern84,_ern85,_ern86,_ern87,_ern88,_ern89]\"}\"\n>"
     ]
    }
   ],
   "source": [
    "sampled_train_data = [train_data.create_tf_dataset_for_client(client_id) for client_id in train_data.client_ids]\n",
    "state, metrics = iterative_process.next(state, sampled_train_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c6355f6b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/124 [00:00<?, ?it/s]2023-04-18 16:59:52.451641: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublas.so.11\n",
      "2023-04-18 16:59:52.899884: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublasLt.so.11\n",
      " 19%|        | 24/124 [55:26<3:23:05, 121.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('zeroing_norm', (_GlobalState(current_estimate=3.1622777, target_quantile=0.98, learning_rate=2.3025851, below_estimate_state=()), ())), ('inner_agg', (_GlobalState(numerator_state=_GlobalState(noise_multiplier=0.48113248, sum_state=_GlobalState(l2_norm_clip=0.4943598, stddev=0.23785256), quantile_estimator_state=_GlobalState(current_estimate=0.4943598, target_quantile=0.5, learning_rate=0.2, below_estimate_state=_GlobalState(numerator_state=_GlobalState(l2_norm_clip=0.5, stddev=3.5), denominator=70.0))), denominator=70.0), ())), ('zeroed_count_agg', ())])\n",
      "Train:55.05063247680664\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-18 17:53:42.278568: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudnn.so.8\n",
      "2023-04-18 17:53:43.475120: I tensorflow/stream_executor/cuda/cuda_dnn.cc:359] Loaded cuDNN version 8004\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8453/8453 [==============================] - 27s 3ms/step - loss: 2.9891e-04 - mean_absolute_error: 0.0099 - mean_squared_error: 2.9891e-04 - root_mean_squared_error: 0.0173 - mean_absolute_percentage_error: 69.8990\n",
      "Saving in /scratch/users/jodelgado/classifier_forecaster/forecasting_classifier_privacy/Federated_Learning/results/experiments/1000_rounds/4ffbd676/25/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-18 17:54:10.968084: W tensorflow/python/util/util.cc:348] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n",
      "WARNING:absl:Found untraced functions such as lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /scratch/users/jodelgado/classifier_forecaster/forecasting_classifier_privacy/Federated_Learning/results/experiments/1000_rounds/4ffbd676/25/model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /scratch/users/jodelgado/classifier_forecaster/forecasting_classifier_privacy/Federated_Learning/results/experiments/1000_rounds/4ffbd676/25/model/assets\n",
      " 40%|      | 49/124 [1:49:45<2:43:59, 131.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('zeroing_norm', (_GlobalState(current_estimate=1.0000002, target_quantile=0.98, learning_rate=2.3025851, below_estimate_state=()), ())), ('inner_agg', (_GlobalState(numerator_state=_GlobalState(noise_multiplier=0.48113248, sum_state=_GlobalState(l2_norm_clip=0.35064292, stddev=0.1687057), quantile_estimator_state=_GlobalState(current_estimate=0.35064292, target_quantile=0.5, learning_rate=0.2, below_estimate_state=_GlobalState(numerator_state=_GlobalState(l2_norm_clip=0.5, stddev=3.5), denominator=70.0))), denominator=70.0), ())), ('zeroed_count_agg', ())])\n",
      "Train:34.69533920288086\n",
      "8453/8453 [==============================] - 24s 3ms/step - loss: 2.1761e-04 - mean_absolute_error: 0.0082 - mean_squared_error: 2.1761e-04 - root_mean_squared_error: 0.0148 - mean_absolute_percentage_error: 55.4479\n",
      "Saving in /scratch/users/jodelgado/classifier_forecaster/forecasting_classifier_privacy/Federated_Learning/results/experiments/1000_rounds/4ffbd676/50/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_4_layer_call_and_return_conditional_losses, lstm_cell_4_layer_call_fn, lstm_cell_4_layer_call_fn, lstm_cell_4_layer_call_and_return_conditional_losses, lstm_cell_4_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /scratch/users/jodelgado/classifier_forecaster/forecasting_classifier_privacy/Federated_Learning/results/experiments/1000_rounds/4ffbd676/50/model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /scratch/users/jodelgado/classifier_forecaster/forecasting_classifier_privacy/Federated_Learning/results/experiments/1000_rounds/4ffbd676/50/model/assets\n",
      " 60%|    | 74/124 [2:43:16<1:40:51, 121.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('zeroing_norm', (_GlobalState(current_estimate=0.31622788, target_quantile=0.98, learning_rate=2.3025851, below_estimate_state=()), ())), ('inner_agg', (_GlobalState(numerator_state=_GlobalState(noise_multiplier=0.48113248, sum_state=_GlobalState(l2_norm_clip=0.30729866, stddev=0.14785136), quantile_estimator_state=_GlobalState(current_estimate=0.30729866, target_quantile=0.5, learning_rate=0.2, below_estimate_state=_GlobalState(numerator_state=_GlobalState(l2_norm_clip=0.5, stddev=3.5), denominator=70.0))), denominator=70.0), ())), ('zeroed_count_agg', ())])\n",
      "Train:33.979881286621094\n",
      "8453/8453 [==============================] - 24s 3ms/step - loss: 1.8656e-04 - mean_absolute_error: 0.0077 - mean_squared_error: 1.8656e-04 - root_mean_squared_error: 0.0137 - mean_absolute_percentage_error: 56.7749\n",
      "Saving in /scratch/users/jodelgado/classifier_forecaster/forecasting_classifier_privacy/Federated_Learning/results/experiments/1000_rounds/4ffbd676/75/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_7_layer_call_and_return_conditional_losses, lstm_cell_7_layer_call_fn, lstm_cell_7_layer_call_fn, lstm_cell_7_layer_call_and_return_conditional_losses, lstm_cell_7_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /scratch/users/jodelgado/classifier_forecaster/forecasting_classifier_privacy/Federated_Learning/results/experiments/1000_rounds/4ffbd676/75/model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /scratch/users/jodelgado/classifier_forecaster/forecasting_classifier_privacy/Federated_Learning/results/experiments/1000_rounds/4ffbd676/75/model/assets\n",
      " 80%|  | 99/124 [3:37:37<53:38, 128.73s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('zeroing_norm', (_GlobalState(current_estimate=0.100000046, target_quantile=0.98, learning_rate=2.3025851, below_estimate_state=()), ())), ('inner_agg', (_GlobalState(numerator_state=_GlobalState(noise_multiplier=0.48113248, sum_state=_GlobalState(l2_norm_clip=0.25863373, stddev=0.12443709), quantile_estimator_state=_GlobalState(current_estimate=0.25863373, target_quantile=0.5, learning_rate=0.2, below_estimate_state=_GlobalState(numerator_state=_GlobalState(l2_norm_clip=0.5, stddev=3.5), denominator=70.0))), denominator=70.0), ())), ('zeroed_count_agg', ())])\n",
      "Train:34.83448028564453\n",
      "8453/8453 [==============================] - 24s 3ms/step - loss: 1.5793e-04 - mean_absolute_error: 0.0067 - mean_squared_error: 1.5793e-04 - root_mean_squared_error: 0.0126 - mean_absolute_percentage_error: 45.2697\n",
      "Saving in /scratch/users/jodelgado/classifier_forecaster/forecasting_classifier_privacy/Federated_Learning/results/experiments/1000_rounds/4ffbd676/100/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_10_layer_call_and_return_conditional_losses, lstm_cell_10_layer_call_fn, lstm_cell_10_layer_call_fn, lstm_cell_10_layer_call_and_return_conditional_losses, lstm_cell_10_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /scratch/users/jodelgado/classifier_forecaster/forecasting_classifier_privacy/Federated_Learning/results/experiments/1000_rounds/4ffbd676/100/model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /scratch/users/jodelgado/classifier_forecaster/forecasting_classifier_privacy/Federated_Learning/results/experiments/1000_rounds/4ffbd676/100/model/assets\n",
      "100%|| 124/124 [4:32:03<00:00, 129.64s/it]\n"
     ]
    }
   ],
   "source": [
    "t = trange(1,NUM_ROUNDS, desc='', leave=True)\n",
    "        \n",
    "for round_num in t:\n",
    "    \n",
    "\n",
    "    start = time()\n",
    "    \n",
    "    train_set = get_training_Q(Q)\n",
    "\n",
    "    state, metrics = iterative_process.next(state, train_set)\n",
    "    \n",
    "    if round_num % 25 == 0:\n",
    "        metrics['train']['round_number'] = int(round_num)\n",
    "        metrics['train']['time'] = time()-start\n",
    "        metrics_train_df = pd.DataFrame(metrics['train'],index=[0])\n",
    "        sys.stdout.flush()\n",
    "        \n",
    "        if Noise != 0.0:\n",
    "            print(state.delta_aggregate_state)\n",
    "\n",
    "        print(f'Train:{metrics_train_df[\"mean_absolute_percentage_error\"].iloc[0]}')\n",
    "        \n",
    "        metrics_test_df = evaluate_federated_model(state)\n",
    "        metrics_test_df['round_number']= round_num\n",
    "        metrics_train_df = metrics_train_df.merge(metrics_test_df, on='round_number', suffixes=('_train','_test'))\n",
    "        results = pd.concat([results,metrics_train_df])\n",
    "       \n",
    "        save_all(results=results,state= state,n_rounds=round_num,config=config,unique_id=unique_id)\n",
    "       \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9d4af1e5-8450-49ed-99bc-674c8355e775",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  MAPE = 25.108067\n",
    "# Q\t0.005794\n",
    "# clients_per_round\t10\n",
    "# total_clients\t1726\n",
    "# noise\t0.10\n",
    "# batch_size\t512\n",
    "# internal_epochs\t10\n",
    "# Optimizer ADAM\n",
    "# 100 rounds "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "674ea1cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_absolute_error_train</th>\n",
       "      <th>mean_squared_error_train</th>\n",
       "      <th>root_mean_squared_error_train</th>\n",
       "      <th>mean_absolute_percentage_error_train</th>\n",
       "      <th>loss_train</th>\n",
       "      <th>round_number</th>\n",
       "      <th>time</th>\n",
       "      <th>loss_test</th>\n",
       "      <th>mean_absolute_error_test</th>\n",
       "      <th>mean_squared_error_test</th>\n",
       "      <th>root_mean_squared_error_test</th>\n",
       "      <th>mean_absolute_percentage_error_test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.006792</td>\n",
       "      <td>0.000192</td>\n",
       "      <td>0.013864</td>\n",
       "      <td>55.050632</td>\n",
       "      <td>0.000192</td>\n",
       "      <td>25</td>\n",
       "      <td>132.741692</td>\n",
       "      <td>0.000299</td>\n",
       "      <td>0.009923</td>\n",
       "      <td>0.000299</td>\n",
       "      <td>0.017289</td>\n",
       "      <td>69.899033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.005065</td>\n",
       "      <td>0.000095</td>\n",
       "      <td>0.009732</td>\n",
       "      <td>34.695339</td>\n",
       "      <td>0.000095</td>\n",
       "      <td>50</td>\n",
       "      <td>124.682097</td>\n",
       "      <td>0.000218</td>\n",
       "      <td>0.008156</td>\n",
       "      <td>0.000218</td>\n",
       "      <td>0.014752</td>\n",
       "      <td>55.447880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.005063</td>\n",
       "      <td>0.000090</td>\n",
       "      <td>0.009490</td>\n",
       "      <td>33.979881</td>\n",
       "      <td>0.000090</td>\n",
       "      <td>75</td>\n",
       "      <td>121.416200</td>\n",
       "      <td>0.000187</td>\n",
       "      <td>0.007681</td>\n",
       "      <td>0.000187</td>\n",
       "      <td>0.013659</td>\n",
       "      <td>56.774860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.004827</td>\n",
       "      <td>0.000083</td>\n",
       "      <td>0.009105</td>\n",
       "      <td>34.834480</td>\n",
       "      <td>0.000083</td>\n",
       "      <td>100</td>\n",
       "      <td>120.216939</td>\n",
       "      <td>0.000158</td>\n",
       "      <td>0.006653</td>\n",
       "      <td>0.000158</td>\n",
       "      <td>0.012567</td>\n",
       "      <td>45.269745</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_absolute_error_train  mean_squared_error_train  \\\n",
       "0                   0.006792                  0.000192   \n",
       "1                   0.005065                  0.000095   \n",
       "2                   0.005063                  0.000090   \n",
       "3                   0.004827                  0.000083   \n",
       "\n",
       "   root_mean_squared_error_train  mean_absolute_percentage_error_train  \\\n",
       "0                       0.013864                             55.050632   \n",
       "1                       0.009732                             34.695339   \n",
       "2                       0.009490                             33.979881   \n",
       "3                       0.009105                             34.834480   \n",
       "\n",
       "   loss_train  round_number        time  loss_test  mean_absolute_error_test  \\\n",
       "0    0.000192            25  132.741692   0.000299                  0.009923   \n",
       "1    0.000095            50  124.682097   0.000218                  0.008156   \n",
       "2    0.000090            75  121.416200   0.000187                  0.007681   \n",
       "3    0.000083           100  120.216939   0.000158                  0.006653   \n",
       "\n",
       "   mean_squared_error_test  root_mean_squared_error_test  \\\n",
       "0                 0.000299                      0.017289   \n",
       "1                 0.000218                      0.014752   \n",
       "2                 0.000187                      0.013659   \n",
       "3                 0.000158                      0.012567   \n",
       "\n",
       "   mean_absolute_percentage_error_test  \n",
       "0                            69.899033  \n",
       "1                            55.447880  \n",
       "2                            56.774860  \n",
       "3                            45.269745  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fd09959",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "refugeeAnalysis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
